{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Modules loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize the input images and resize to a manageable size\n",
    "alpha = -0.5\n",
    "beta = 0.5\n",
    "x_size = 32\n",
    "y_size = 16\n",
    "\n",
    "def preprocess_image(image):\n",
    "    copy_image = np.uint8(image)\n",
    "    norm_image = cv2.normalize(copy_image, copy_image, alpha=alpha, beta=beta, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    \n",
    "    out_image = cv2.resize(norm_image, (x_size, y_size), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    #if(flatten_input):\n",
    "    #    out_image = np.array(out_image, dtype=np.float32).flatten()\n",
    "    \n",
    "    return out_image\n",
    "\n",
    "def preprocess(array):\n",
    "    normalized = []\n",
    "    \n",
    "    for i in range(len(array)):\n",
    "        normalized.append(preprocess_image(array[i]))\n",
    "                    \n",
    "    return np.array(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_data_from_folder(folder_path):\n",
    "    image_paths = []\n",
    "    image_data = []\n",
    "    steering_angles = []\n",
    "\n",
    "    driving_log = np.genfromtxt(os.path.join(folder_path, 'driving_log.csv'), delimiter=',', dtype=\"S256,S256,S256,f8,f8,f8,f8\")\n",
    "    base_name = os.path.basename(folder_path)\n",
    "    for record in driving_log:\n",
    "        center_image = record[0].decode(\"utf-8\")\n",
    "        image_rel_path = center_image.rsplit(base_name + '/')[1]\n",
    "        image_full_path = os.path.join(folder_path, image_rel_path)\n",
    "\n",
    "        steering_angle = record[3]\n",
    "\n",
    "        image = mpimg.imread(image_full_path)\n",
    "        \n",
    "        image_paths.append(image_full_path)\n",
    "        image_data.append(image)\n",
    "        steering_angles.append(steering_angle)\n",
    "    \n",
    "    return np.array(image_paths), np.array(image_data), np.array(steering_angles)\n",
    "\n",
    "folder_list = ['data/t1', 'data/t1_extra']\n",
    "\n",
    "print(\"Loading data from {0} folders:\".format(len(folder_list)))\n",
    "\n",
    "image_paths = []\n",
    "image_data = []\n",
    "steering_angles = []\n",
    "\n",
    "image_shape = None\n",
    "\n",
    "for folder_path in folder_list:\n",
    "    image_paths_cur, image_data_cur, steering_angles_cur = extract_data_from_folder(folder_path)\n",
    "    \n",
    "    image_paths.append(image_paths_cur)\n",
    "    image_data.append(image_data_cur)\n",
    "    steering_angles.append(steering_angles_cur)\n",
    "    \n",
    "    num_training = len(image_paths_cur)\n",
    "    \n",
    "    if(image_shape == None):\n",
    "        image_shape =  image_data_cur[0].shape\n",
    "    \n",
    "    assert(image_data_cur[0].shape == image_shape), \"Data from folders need to have the same shape\"\n",
    "    \n",
    "    print(\"  Folder '{0}': Training examples={1}, Image shape={2}\".format(folder_path, num_training, image_data_cur[0].shape))\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Preprocessing input data...\")\n",
    "\n",
    "image_data_proc = []\n",
    "for image_folder_data in image_data:\n",
    "    image_data_proc_cur = preprocess(image_folder_data)\n",
    "    image_data_proc.append(image_data_proc_cur)\n",
    "\n",
    "print('Normalized images and resized data from a shape of', image_data[0][0].shape, 'to a shape of', image_data_proc[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "num_folders = len(folder_list)\n",
    "for i in range(num_folders):\n",
    "    subplot = plt.subplot(num_folders, 2, 2*i+1)\n",
    "    subplot.imshow(image_data[i][0])\n",
    "    subplot.set_title(image_paths[i][0])\n",
    "\n",
    "    subplot = plt.subplot(num_folders, 2, 2*i+2)\n",
    "    subplot.imshow(image_data_proc[i][0])\n",
    "    #subplot.set_title(image_paths_1[0])\n",
    "#plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "for i in range(num_folders):\n",
    "    subplot = plt.subplot(num_folders, 1, i+1)\n",
    "    subplot.plot(steering_angles[i], 'b')\n",
    "    subplot.set_xlim([0, len(steering_angles[i])])\n",
    "    subplot.set_ylim([-1, 1])\n",
    "    subplot.set_title(\"Steering Angle for '{0}' (degrees)\".format(folder_list[i]))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Merging data from all folders...\")\n",
    "\n",
    "X_train = np.concatenate((image_data_proc))\n",
    "y_train = np.concatenate((steering_angles))\n",
    "\n",
    "print(\"Size of training data is now: {0}\".format(len(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Augmenting data with flipped images and steering angles...\")\n",
    "\n",
    "initial_size = len(X_train)\n",
    "\n",
    "extra_images = []\n",
    "extra_angles = []\n",
    "for i in range(initial_size):\n",
    "    flipped_image = cv2.flip(X_train[i,:], 1)\n",
    "    extra_images.append(flipped_image)\n",
    "    extra_angles.append(-y_train[i])\n",
    "\n",
    "subplot = plt.subplot(1, 2, 1)\n",
    "subplot.imshow(X_train[0, :])\n",
    "subplot.set_title(\"Original: {0} degrees\".format(y_train[0]))\n",
    "subplot = plt.subplot(1, 2, 2)\n",
    "subplot.imshow(extra_images[0])\n",
    "subplot.set_title(\"Flipped: {0} degrees\".format(extra_angles[0]))\n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "subplot = plt.subplot(1, 2, 1)\n",
    "subplot.hist(y_train, 50, histtype='stepfilled')\n",
    "subplot.set_title(\"Before augmentation\")\n",
    "subplot.set_yscale('log')\n",
    "    \n",
    "X_train = np.concatenate((X_train, np.array(extra_images)))\n",
    "y_train = np.concatenate((y_train, np.array(extra_angles)))\n",
    "\n",
    "subplot = plt.subplot(1, 2, 2)\n",
    "subplot.hist(y_train, 50, histtype='stepfilled')\n",
    "subplot.set_title(\"After augmentation\")\n",
    "subplot.set_yscale('log')\n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Size of training data is now: {0} ({1:5.2f}% of the initial size)\".format(len(X_train), 100. * len(X_train) / initial_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Splitting the training data into training, validation and test sets...\")\n",
    "\n",
    "n_total = len(X_train)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=314)\n",
    "print(\"Training size={0} ({1:5.2f}%), Validation size={2} ({3:5.2f}%) Test size={4} ({5:5.2f}%)\".\n",
    "      format(len(X_train), (100. * len(X_train) / n_total),\n",
    "             len(X_val),  (100. * len(X_val) / n_total),\n",
    "             len(X_test), (100. * len(X_test) / n_total)))\n",
    "\n",
    "assert(round(np.mean(X_train)) == 0), \"The mean of the input data is: %f\" % np.mean(X_train)\n",
    "assert(math.isclose(np.min(X_train), -0.5, abs_tol=1e-5) and math.isclose(np.max(X_train), 0.5, abs_tol=1e-5)), \"The range of the input data is: %.1f to %.1f\" % (np.min(X_train), np.max(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_rows_proc = X_train[0].shape[0]\n",
    "num_cols_proc = X_train[0].shape[1]\n",
    "num_channels_proc = X_train[0].shape[2]\n",
    "\n",
    "input_shape = (num_rows_proc, num_cols_proc, num_channels_proc)\n",
    "nb_filters = 32\n",
    "kernel_size = (3, 3)\n",
    "pool_size = (2, 2)\n",
    "n_classes = 1\n",
    "\n",
    "print(\"Building model with: input_shape={0}, nb_filters={1}, kernel_size={2} pool_size={3} nb_classes={4}\".\n",
    "      format(input_shape, nb_filters, kernel_size, pool_size, n_classes))\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode='valid', input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, name='fc1'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(128, name='fc2'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(64, name='fc3'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(32, name='fc4'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(n_classes, name='output'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "nb_epoch = 10\n",
    "\n",
    "print(\"Training with batch_size={0} and nb_epoch={1}...\".format(batch_size, nb_epoch))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam())\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=1,\n",
    "                    validation_data=(X_val, y_val))\n",
    "\n",
    "print(\"Training ended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Evaluating the model performance on the test set...\")\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "print(\"Test cost:\", score)\n",
    "\n",
    "acc_plot = plt.subplot(212)\n",
    "acc_plot.plot(np.arange(1, nb_epoch + 1), history.history['loss'], 'r', label='Training')\n",
    "acc_plot.plot(np.arange(1, nb_epoch + 1), history.history['val_loss'], 'b', label='Validation')\n",
    "acc_plot.set_xlim([0, nb_epoch + 1])\n",
    "#acc_plot.set_ylim([0, 100])\n",
    "#acc_plot.set_yscale('log')\n",
    "acc_plot.legend(loc=1)\n",
    "acc_plot.set_title('Cost')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(json.dumps(model_json))\n",
    "        \n",
    "model.save_weights(\"model.h5\")\n",
    "\n",
    "print(\"Model and weights saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
