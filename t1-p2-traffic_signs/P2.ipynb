{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "## Deep Learning\n",
    "\n",
    "## Project: Build a Traffic Sign Recognition Classifier\n",
    "\n",
    "In this notebook, a template is provided for you to implement your functionality in stages which is required to successfully complete this project. If additional code is required that cannot be included in the notebook, be sure that the Python code is successfully imported and included in your submission, if necessary. Sections that begin with **'Implementation'** in the header indicate where you should begin your implementation for your project. Note that some sections of implementation are optional, and will be marked with **'Optional'** in the header.\n",
    "\n",
    "In addition to implementing code, there will be questions that you must answer which relate to the project and your implementation. Each section where you will answer a question is preceded by a **'Question'** header. Carefully read each question and provide thorough answers in the following text boxes that begin with **'Answer:'**. Your project submission will be evaluated based on your answers to each of the questions and the implementation you provide.\n",
    "\n",
    ">**Note:** Code and Markdown cells can be executed using the **Shift + Enter** keyboard shortcut. In addition, Markdown cells can be edited by typically double-clicking the cell to enter edit mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: Dataset Exploration\n",
    "\n",
    "Visualize the German Traffic Signs Dataset. This is open ended, some suggestions include: plotting traffic signs images, plotting the count of each sign, etc. Be creative!\n",
    "\n",
    "\n",
    "The pickled data is a dictionary with 4 key/value pairs:\n",
    "\n",
    "- features -> the images pixel values, (width, height, channels)\n",
    "- labels -> the label of the traffic sign\n",
    "- sizes -> the original width and height of the image, (width, height)\n",
    "- coords -> coordinates of a bounding box around the sign in the image, (x1, y1, x2, y2). Based the original image (not the resized version)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's first load all the modules we're going to need\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "\n",
    "# TODO: fill this in based on where you saved the training and testing data\n",
    "training_file = 'data/train.p'\n",
    "testing_file = 'data/test.p'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### To start off let's do a basic data summary.\n",
    "\n",
    "# TODO: number of training examples\n",
    "n_train = len(X_train)\n",
    "\n",
    "# TODO: number of testing examples\n",
    "n_test = len(X_test)\n",
    "\n",
    "# TODO: what's the shape of an image?\n",
    "image_shape = X_train[0].shape\n",
    "\n",
    "# TODO: how many classes are in the dataset\n",
    "# y_train_unique_indices contains the index of the first occurrence of each class in y_train\n",
    "# We'll need this in order to plot a sample image for each label\n",
    "y_train_unique, y_train_unique_indices = np.unique(y_train, return_index=True)\n",
    "n_classes = len(y_train_unique)\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Data exploration visualization goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "# Load the label names (useful for plotting, and later for displaying predictions)\n",
    "label_names = np.genfromtxt('signnames.csv', delimiter=',', dtype=\"i8,S256\", skip_header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Getting the count of each label in both training and test data\n",
    "y_train_bincount = np.bincount(y_train)\n",
    "y_test_bincount = np.bincount(y_test)\n",
    "y_train_binperc = np.divide(y_train_bincount, n_train)\n",
    "y_test_binperc = np.divide(y_test_bincount, n_test)\n",
    "\n",
    "assert len(y_train_bincount) == len(y_test_bincount),\\\n",
    "    'Training and test label sets should have the same number of labels'\n",
    "\n",
    "print('Showing label distribution in training and test data:')\n",
    "for i in range(len(y_train_bincount)):\n",
    "    print('  Label {0:2d} {1:53s} - Training: {2:4d} ({3:5.2f}%) Test: {4:4d} ({5:5.2f}%)'\n",
    "          .format(i, label_names[i][1], y_train_bincount[i], 100 * y_train_binperc[i], y_test_bincount[i], 100 * y_test_binperc[i]))\n",
    "\n",
    "# Showing the label distribution in the training and test samples\n",
    "%matplotlib inline\n",
    "plot = plt.subplot(111)\n",
    "plot.set_title('Label Occurrences (%)')\n",
    "plot.plot(y_train_binperc * 100, 'r', label='Training')\n",
    "plot.plot(y_test_binperc * 100, 'b', label='Test')\n",
    "plot.set_xlim([-1, n_classes])\n",
    "plot.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show the first occurrence of each label in the data set\n",
    "plt.rcParams[\"figure.figsize\"] = [12, 36]\n",
    "n_img_to_show = n_classes\n",
    "num_cols = 4\n",
    "num_rows = np.ceil(n_img_to_show / num_cols)\n",
    "k = 1\n",
    "print('Showing a sample of', n_img_to_show, 'images:')\n",
    "for i in y_train_unique_indices:\n",
    "    image = X_train[i]\n",
    "    image_label_index = y_train[i]\n",
    "    image_label_text = label_names[image_label_index][1]\n",
    "    subplot = plt.subplot(num_rows, num_cols, k)\n",
    "    subplot.imshow(image)\n",
    "    subplot.set_title(image_label_text)\n",
    "    k = k + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Step 2: Design and Test a Model Architecture\n",
    "\n",
    "Design and implement a deep learning model that learns to recognize traffic signs. Train and test your model on the [German Traffic Sign Dataset](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset).\n",
    "\n",
    "There are various aspects to consider when thinking about this problem:\n",
    "\n",
    "- Your model can be derived from a deep feedforward net or a deep convolutional network.\n",
    "- Play around preprocessing techniques (normalization, rgb to grayscale, etc)\n",
    "- Number of examples per label (some have more than others).\n",
    "- Generate fake data.\n",
    "\n",
    "Here is an example of a [published baseline model on this problem](http://yann.lecun.com/exdb/publis/pdf/sermanet-ijcnn-11.pdf). It's not required to be familiar with the approach used in the paper but, it's good practice to try to read papers like these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Preprocess the data here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "# Convert to grayscale, normalize, and flatten to 1D\n",
    "alpha = -0.5\n",
    "beta = 0.5\n",
    "\n",
    "def preprocess_image(image):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray_norm = cv2.normalize(gray_image, alpha, beta, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    gray_flat = np.array(gray_norm, dtype=np.float32).flatten()\n",
    "    \n",
    "    return gray_flat\n",
    "\n",
    "def preprocess(array):\n",
    "    normalized = []\n",
    "    \n",
    "    for i in range(len(array)):\n",
    "        normalized.append(preprocess_image(array[i]))\n",
    "                    \n",
    "    return np.array(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Preprocess the features\n",
    "\n",
    "X_train_gray_norm = preprocess(X_train)\n",
    "X_test_gray_norm = preprocess(X_test)\n",
    "\n",
    "print('Normalized images from a shape of', X_train[0].shape, 'to a shape of', X_train_gray_norm[0].shape)\n",
    "\n",
    "# One-hot encode the labels and convert to float32\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "encoder.fit(y_train)\n",
    "y_train_hot = encoder.transform(y_train)\n",
    "y_test_hot = encoder.transform(y_test)\n",
    "y_train_hot = y_train_hot.astype(np.float32)\n",
    "y_test_hot = y_test_hot.astype(np.float32)\n",
    "\n",
    "print('One-hot encoded labels from', y_train[0].shape, 'to a shape of', y_train_hot[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For our previous small sample, let's plot the processed images against the originals to make\n",
    "# sure all went well\n",
    "plt.rcParams[\"figure.figsize\"] = [12, 150]\n",
    "num_cols = 2\n",
    "num_rows = np.ceil((n_img_to_show * 2) / num_cols)\n",
    "k = 1\n",
    "print('Displaying the originals and the preprocessed images for the previous sample of', n_img_to_show, 'images:')\n",
    "for i in y_train_unique_indices:\n",
    "    image = X_train[i]\n",
    "    image_gray_norm = X_train_gray_norm[i]\n",
    "    \n",
    "    image_label_index = y_train[i]\n",
    "    image_label_text = label_names[image_label_index][1]\n",
    "    \n",
    "    subplot = plt.subplot(num_rows, num_cols, k)\n",
    "    subplot.imshow(image)\n",
    "    subplot.set_title(image_label_text)\n",
    "    \n",
    "    subplot = plt.subplot(num_rows, num_cols, k + 1)\n",
    "    im = np.reshape(image_gray_norm, (image.shape[0], image.shape[1]))\n",
    "    subplot.imshow(im, cmap='gray')\n",
    "    subplot.set_title(image_label_text)\n",
    "    \n",
    "    k = k + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 \n",
    "\n",
    "_Describe the techniques used to preprocess the data._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "* Converted each feature image into grayscale\n",
    "* Normalized the gray image to the [-0.5, 0.5] range\n",
    "* Flattened the gray normalized image into a 1-dimensional vector\n",
    "* One-hot encoded the labels (converted each label from an integer value into a 1-dimensional binary vector that only has the corresponding bit turned on).\n",
    "\n",
    "This was applied to both the training and the test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Generate data additional (if you want to!)\n",
    "### and split the data into training/validation/testing sets here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "# Not additional data generated. See answer below.\n",
    "\n",
    "# Splitting the data\n",
    "\n",
    "features_training = X_train_gray_norm\n",
    "labels_training = y_train_hot\n",
    "features_test = X_test_gray_norm\n",
    "labels_test = y_test_hot\n",
    "\n",
    "num_features = features_training[0].shape[0]\n",
    "num_labels = labels_training[0].shape[0]\n",
    "\n",
    "assert features_training[0].shape == features_test[0].shape,\\\n",
    "    'Training and test feature sets must have the same shape'\n",
    "assert labels_training[0].shape == labels_test[0].shape,\\\n",
    "    'Training and test label sets must have the same shape'\n",
    "assert len(features_training) == len(labels_training),\\\n",
    "    'Training features and labels must have the same size'\n",
    "assert len(features_test) == len(labels_test),\\\n",
    "    'Test features and labels must have the same size'\n",
    "\n",
    "total_training = len(features_training)\n",
    "total_test = len(features_test)\n",
    "total = len(features_training) + len(features_test)\n",
    "print('Preparing the data for training:')\n",
    "print('\\tTotal:', total)\n",
    "print('\\t{0:6d} ({1:5.2f}%) training examples'\\\n",
    "      .format(total_training, 100. * total_training / total))\n",
    "print('\\t{0:6d} ({1:5.2f}%) test examples'\\\n",
    "      .format(total_test, 100. * total_test / total))\n",
    "print('Shape of features is', features_training[0].shape, ', and labels is', labels_training[0].shape)\n",
    "\n",
    "validation_ratio = 0.05\n",
    "random_state = 20161128\n",
    "features_training, features_validation, labels_training, labels_validation = train_test_split(\n",
    "    features_training,\n",
    "    labels_training,\n",
    "    test_size=validation_ratio,\n",
    "    random_state=random_state)\n",
    "\n",
    "print('Extracted {0:.2f}% from the training sample to act as validation'.format(validation_ratio * 100))\n",
    "\n",
    "total_training = len(features_training)\n",
    "total_validation = len(features_validation)\n",
    "total_test = len(features_test)\n",
    "total = len(features_training) + len(features_validation) + len(features_test)\n",
    "print('\\tTotal:', total)\n",
    "print('\\t{0:6d} ({1:5.2f}%) training examples'\\\n",
    "      .format(total_training, 100. * total_training / total))\n",
    "print('\\t{0:6d} ({1:5.2f}%) validation examples'\\\n",
    "      .format(total_validation, 100. * total_validation / total))\n",
    "print('\\t{0:6d} ({1:5.2f}%) test examples'\\\n",
    "      .format(total_test, 100. * total_test / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "_Describe how you set up the training, validation and testing data for your model. If you generated additional data, why?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "I extracted 5% from the training examples to act as a validation set.\n",
    "\n",
    "***Additionnal data***\n",
    "\n",
    "I did not generate additional data here. But it would be useful for the model to include some fake data that will cover cases encountered when running the model in real conditions. These conditions are not accounted for by the current data, and including them in the training will make the model much more robust in production.\n",
    "\n",
    "For example:\n",
    "* Resolution change: by blurring or sharpening images over a reasonble range. This will cover focus issues in real conditions.\n",
    "* Distortion around an axis that goes through the center of the image (no need to do it for an axis that does not go through the center since we can always re-center the sign during preprocessing). This is useful for cases when the sign does not face the camera properly.\n",
    "* Rotation around the center, over a reasonable range. This will take account of signs that are slightly bent or turned. And for windy conditions.\n",
    "* Saturation and noise, to cover bright and low light conditions.\n",
    "* Adding artefacts to account for rain. snow, sand, fog, smoke, etc.\n",
    "* Occlude parts of the image, since real conditions can have a vehicle, a tree, a building, etc, obstruct parts of the sign.\n",
    "* Color change to account for sign discoloration.\n",
    "* Extra artefacts to account for vandalized or old signs (graffitis for example).\n",
    "\n",
    "It's possible to use OpenCV to generate such data, with tweakable ratios of how much each condition contributes to the total. Obviously, the difficulty in generating such data varies by condition, so it'd be useful to start by the cases that are easiest to generate and evaluate their impact during the training. Before investing much effort in covering all the extra conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Define your architecture here.\n",
    "### Feel free to use as many code cells as needed\n",
    "\n",
    "# This is a simple linear model I used for testing the pipeline (inspired from the Tensorflow Lab)\n",
    "def linearModel(num_features, num_labels):\n",
    "    x = tf.placeholder(tf.float32)\n",
    "    y = tf.placeholder(tf.float32)\n",
    "\n",
    "    weights = tf.Variable(tf.truncated_normal((num_features, num_labels)))\n",
    "    biases = tf.Variable(tf.zeros(num_labels))\n",
    "    \n",
    "    logits = tf.matmul(x, weights) + biases\n",
    "    \n",
    "    return x, y, logits\n",
    "\n",
    "# This is the perceptron model from the course\n",
    "def perceptron(n_input, n_classes):\n",
    "    n_hidden_layer = 256\n",
    "\n",
    "    weights = {\n",
    "        'hidden_layer': tf.Variable(tf.random_normal([n_input, n_hidden_layer])),\n",
    "        'out': tf.Variable(tf.random_normal([n_hidden_layer, n_classes]))\n",
    "    }\n",
    "    biases = {\n",
    "        'hidden_layer': tf.Variable(tf.random_normal([n_hidden_layer])),\n",
    "        'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "    }\n",
    "    \n",
    "    x = tf.placeholder(tf.float32)\n",
    "    y = tf.placeholder(tf.float32)\n",
    "\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_1 = tf.nn.relu(tf.matmul(x, weights['hidden_layer']) + biases['hidden_layer'])\n",
    "    \n",
    "    # Output layer with linear activation\n",
    "    logits = tf.matmul(layer_1, weights['out']) + biases['out']\n",
    "    \n",
    "    return x, y, logits\n",
    "\n",
    "# ConvNet\n",
    "def convnet(n_input, n_classes):\n",
    "    x = tf.placeholder(tf.float32, [None, n_input])\n",
    "    y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "    \n",
    "    # Create some wrappers for simplicity\n",
    "    def conv2d(x, W, b, strides=1):\n",
    "        # Conv2D wrapper, with bias and relu activation\n",
    "        x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "        x = tf.nn.bias_add(x, b)\n",
    "        return tf.nn.relu(x)\n",
    "\n",
    "    def maxpool2d(x, k=2):\n",
    "        # MaxPool2D wrapper\n",
    "        return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')\n",
    "\n",
    "    # Create model\n",
    "    def conv_net(x, weights, biases, dropout_conv, dropout):\n",
    "        # Reshape input picture\n",
    "        x = tf.reshape(x, shape=[-1, 32, 32, 1])# Modified here\n",
    "\n",
    "        # Convolution Layer\n",
    "        conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "        # Max Pooling (down-sampling)\n",
    "        conv1 = maxpool2d(conv1, k=2)\n",
    "        conv1 = tf.nn.dropout(conv1, dropout_conv)\n",
    "\n",
    "        # Convolution Layer\n",
    "        conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "        # Max Pooling (down-sampling)\n",
    "        conv2 = maxpool2d(conv2, k=2)\n",
    "        conv2 = tf.nn.dropout(conv2, dropout_conv)\n",
    "        \n",
    "        # Convolution Layer\n",
    "        conv3 = conv2d(conv2, weights['wc3'], biases['bc3'])\n",
    "        # Max Pooling (down-sampling)\n",
    "        conv3 = maxpool2d(conv3, k=2)\n",
    "        conv3 = tf.nn.dropout(conv3, dropout_conv)\n",
    "\n",
    "        # Fully connected layer\n",
    "        # Reshape conv2 output to fit fully connected layer input\n",
    "        fc1 = tf.reshape(conv3, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "        fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "        fc1 = tf.nn.relu(fc1)\n",
    "        # Apply Dropout\n",
    "        fc1 = tf.nn.dropout(fc1, dropout)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        # Reshape conv2 output to fit fully connected layer input\n",
    "        #fc2 = tf.reshape(fc1, [-1, weights['wd2'].get_shape().as_list()[0]])\n",
    "        fc2 = tf.add(tf.matmul(fc1, weights['wd2']), biases['bd2'])\n",
    "        fc2 = tf.nn.relu(fc2)\n",
    "        # Apply Dropout\n",
    "        fc2 = tf.nn.dropout(fc2, dropout)\n",
    "        \n",
    "        # Output, class prediction\n",
    "        out = tf.add(tf.matmul(fc2, weights['out']), biases['out'])\n",
    "        return out\n",
    "\n",
    "    # Store layers weight & bias\n",
    "    weights = {\n",
    "        # 3x3 conv, 1 input, 32 outputs\n",
    "        'wc1': tf.Variable(tf.truncated_normal([3, 3, 1, 32])),\n",
    "        # 3x3 conv, 32 inputs, 64 outputs\n",
    "        'wc2': tf.Variable(tf.truncated_normal([3, 3, 32, 64])),\n",
    "        # 3x3 conv, 64 inputs, 128 outputs\n",
    "        'wc3': tf.Variable(tf.truncated_normal([3, 3, 64, 128])),\n",
    "        # fully connected, 4*4*128 inputs, 256 outputs\n",
    "        'wd1': tf.Variable(tf.truncated_normal([4*4*128, 256])),\n",
    "        # fully connected, 256 inputs, 512 outputs\n",
    "        'wd2': tf.Variable(tf.truncated_normal([256, 512])),\n",
    "        # 512 inputs, n_classes outputs (class prediction)\n",
    "        'out': tf.Variable(tf.truncated_normal([512, n_classes]))\n",
    "    }\n",
    "\n",
    "    biases = {\n",
    "        'bc1': tf.Variable(tf.zeros([32])),\n",
    "        'bc2': tf.Variable(tf.zeros([64])),\n",
    "        'bc3': tf.Variable(tf.zeros([128])),\n",
    "        'bd1': tf.Variable(tf.zeros([256])),\n",
    "        'bd2': tf.Variable(tf.zeros([512])),\n",
    "        'out': tf.Variable(tf.zeros([n_classes]))\n",
    "    }\n",
    "\n",
    "    # Construct model\n",
    "    logits = conv_net(x, weights, biases, keep_prob_conv, keep_prob)\n",
    "    \n",
    "    return x, y, logits\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, name, function, path):\n",
    "        self.name = name\n",
    "        self.function = function\n",
    "        self.path = path\n",
    "\n",
    "#model_to_use = Model('Linear', linearModel, 'models/linear.cpkt')\n",
    "#model_to_use = Model('Percepetron', perceptron, 'models/percepetron.cpkt')\n",
    "model_to_use = Model('ConvNet', convnet, 'models/convnet.cpkt')\n",
    "\n",
    "keep_prob_conv = tf.placeholder(tf.float32) #dropout (keep probability for convolutional layers)\n",
    "keep_prob = tf.placeholder(tf.float32) #dropout (keep probability for fully-connected layers)\n",
    "\n",
    "features, labels, logits = model_to_use.function(num_features, num_labels)\n",
    "\n",
    "prediction = tf.nn.softmax(logits)\n",
    "#cross_entropy = \n",
    "#cost = tf.reduce_mean(-tf.reduce_sum(y * tf.log(prediction), reduction_indices=1))\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, labels))\n",
    "\n",
    "# Determine if the predictions are correct\n",
    "is_correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(labels, 1))\n",
    "#correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "\n",
    "# Accurracy of the predictions\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct_prediction, tf.float32))\n",
    "\n",
    "print('Created the model to be used: {0}'.format(model_to_use.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "_What does your final architecture look like? (Type of model, layers, sizes, connectivity, etc.)  For reference on how to build a deep neural network using TensorFlow, see [Deep Neural Network in TensorFlow\n",
    "](https://classroom.udacity.com/nanodegrees/nd013/parts/fbf77062-5703-404e-b60c-95b78b2f3f9e/modules/6df7ae49-c61c-4bb2-a23e-6527e69209ec/lessons/b516a270-8600-4f93-a0a3-20dfeabe5da6/concepts/83a3a2a2-a9bd-4b7b-95b0-eb924ab14432) from the classroom._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "_The code of the models I experimented with is often inspired from the code examples given in the classroom._\n",
    "\n",
    "I experimented with different architectures (see below for details), but the final model is a CNN with three 3x3 convolutional layers with RELU activation, each followed by 2x2 max pooling. The final two layers are fully connected layers with RELU activation of a size of 256 and 512 respectively.\n",
    "\n",
    "I tried to add high dropout after each max pooling, and average dropout after the fully connected layers. This last step was meant to avoid the model from overfitting (which happens very quickly without dropout). See below for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Train your model here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "# The training loop here, with batching and final accurracy visualization is inspired from the\n",
    "# Tensorflow Lab code.\n",
    "\n",
    "# For linear\n",
    "#epochs = 20\n",
    "#batch_size = 1000\n",
    "#slearning_rate = 0.1\n",
    "\n",
    "# For perceptron\n",
    "#epochs = 2000\n",
    "#batch_size = 1000\n",
    "#learning_rate = 0.1\n",
    "\n",
    "# For convnet\n",
    "epochs = 1000\n",
    "batch_size = 1024\n",
    "learning_rate = 0.0001\n",
    "dropout_conv = 1.\n",
    "dropout = 1.\n",
    "\n",
    "# Measurements use for graphing cost and accuracy\n",
    "log_batch_step = 50\n",
    "batches = []\n",
    "cost_batch = []\n",
    "training_acc_batch = []\n",
    "validation_acc_batch = []\n",
    "\n",
    "# Feed dicts for training, validation, and test\n",
    "training_feed_dict = {features: features_training, labels: labels_training, keep_prob_conv: dropout_conv, keep_prob: dropout}\n",
    "validation_feed_dict = {features: features_validation, labels: labels_validation, keep_prob_conv: 1, keep_prob: 1}\n",
    "test_feed_dict = {features: features_test, labels: labels_test, keep_prob_conv: 1, keep_prob: 1}\n",
    "\n",
    "print(\"Training model '{0}'...\".format(model_to_use.name))\n",
    "print('epochs={0} batch_size={1} learning_rate={2}'.format(epochs, batch_size, learning_rate))\n",
    "\n",
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(tf.initialize_all_variables())\n",
    "    batch_count = int(np.ceil(len(features_training)/batch_size))\n",
    "    \n",
    "    for epoch_i in tqdm_notebook(range(epochs), desc='Epochs'):\n",
    "        for batch_i in tqdm_notebook(range(batch_count), desc='Batches', leave=False):\n",
    "            # Get a batch of training features and labels\n",
    "            batch_start = batch_i * batch_size\n",
    "            \n",
    "            batch_features = features_training[batch_start:batch_start + batch_size]\n",
    "            batch_labels = labels_training[batch_start:batch_start + batch_size]\n",
    "            \n",
    "            batch_feed_dict = {features: batch_features, labels: batch_labels, keep_prob_conv: dropout_conv, keep_prob: dropout}\n",
    "\n",
    "            # Run optimizer and get cost\n",
    "            _, current_cost = session.run([optimizer, cost], feed_dict=batch_feed_dict)\n",
    "\n",
    "            # Log every 50 batches\n",
    "            if not batch_i % log_batch_step:\n",
    "                training_accuracy = session.run(accuracy, feed_dict=batch_feed_dict) #session.run(accuracy, feed_dict=training_feed_dict)\n",
    "                validation_accuracy = session.run(accuracy, feed_dict=validation_feed_dict)\n",
    "\n",
    "                previous_batch = batches[-1] if batches else 0\n",
    "                batches.append(epoch_i * batch_count + batch_i)\n",
    "                cost_batch.append(current_cost)\n",
    "                training_acc_batch.append(training_accuracy * 100)\n",
    "                validation_acc_batch.append(validation_accuracy * 100)\n",
    "                \n",
    "                print(\"Epoch={0:4d} Batch={1:3d} Cost={2:13.6f} Accuracy={3:5.2f}% Validation={4:5.2f}%\".\n",
    "                      format(epoch_i, batch_i, current_cost, training_acc_batch[-1], validation_acc_batch[-1]))\n",
    "\n",
    "    # Compute the final costs and accurracies\n",
    "    training_cost = cost_batch[-1]#session.run(cost, feed_dict=training_feed_dict)\n",
    "    validation_cost = session.run(cost, feed_dict=validation_feed_dict)\n",
    "    test_cost = session.run(cost, feed_dict=test_feed_dict)\n",
    "    \n",
    "    training_accuracy = training_acc_batch[-1]/100 #session.run(accuracy, feed_dict=training_feed_dict)\n",
    "    validation_accuracy = session.run(accuracy, feed_dict=validation_feed_dict)\n",
    "    test_accuracy = session.run(accuracy, feed_dict=test_feed_dict)\n",
    "    \n",
    "    # Persisting the model so that we can re-use it later\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(session, model_to_use.path)\n",
    "    print('Final accurracies and costs:')\n",
    "    print('  Training  : {0:5.2f}%, {1}'.format(training_accuracy * 100, training_cost))\n",
    "    print('  Validation: {0:5.2f}%, {1}'.format(validation_accuracy * 100, validation_cost))\n",
    "    print('  Test      : {0:5.2f}%, {1}'.format(test_accuracy * 100, test_cost))\n",
    "    print(\"Trained model '{0}' saved to '{1}\".format(model_to_use.name, save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot cost along with training and validation accurraccies\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# We plot the cost with a log scale to better resolve the smallest values\n",
    "cost_plot = plt.subplot(211)\n",
    "cost_plot.plot(batches, cost_batch, 'g')\n",
    "cost_plot.set_xlim([batches[0], batches[-1]])\n",
    "cost_plot.set_yscale('log')\n",
    "cost_plot.set_title('Cost')\n",
    "\n",
    "acc_plot = plt.subplot(212)\n",
    "acc_plot.plot(batches, training_acc_batch, 'r', label='Training')\n",
    "acc_plot.plot(batches, validation_acc_batch, 'b', label='Validation')\n",
    "acc_plot.set_xlim([batches[0], batches[-1]])\n",
    "acc_plot.set_ylim([0, 100])\n",
    "acc_plot.legend(loc=2)\n",
    "acc_plot.set_title('Accuracy (%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "_How did you train your model? (Type of optimizer, batch size, epochs, hyperparameters, etc.)_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "_The code of the loop I used for training the pipeline is inspired from the Tensorflow Lab code._\n",
    "\n",
    "I batched the training data in sets of 1024 pairs for 1000 epochs (~37000 iterations). I used an AdamOptimizer for the optimization step. I printed the batch training accurracy and cost, along with the validation accuracy every 50 steps to monitor the convergence of the algorithm. And finally printed the accuracy on the test dataset, plotted the progress of cost and accurracies with the optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "\n",
    "_What approach did you take in coming up with a solution to this problem?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "At the beginning, I tried to run a simple one hidden-layer neural network, based on the lessons and on the examples therein, such as the multi-layer perceptron. However, I encountered issues due to wrong normalization, incorrect vector sizes and unfamiliarity with TensorFlow and this type of optimization. These made the adaptation of such a model to my case challenging.\n",
    "\n",
    "I therefore decided to go back to the simple linear model provided in the Tensorflow Lab and try to adapt my current pipeline to provide the right input to the model. Once this worked, and had a reasonable training output (80% accuracy on the test set after 100 epochs and a learning rate of 0.1 for a batch size of 128), I decided to go back to a non-linear model. Interestingly, this model gave quite good results with the external (web) dataset.\n",
    "\n",
    "I returned to the multi-layer perceptron, and with insight gained from the accumulated experience thus far, I was able to apply the necessary changes to make it work. It converged very quickly and had a high accuracy on the training set (> 90%), a little lower on the validation set, and around 70% on the test set. This showed that it was likely overfitting the data. And not surprisingly, the results on the external images were less good than with the linear model.\n",
    "\n",
    "I was finally ready to try a CNN architecture, similar to the one provided in the course. I attempted to run the code examples and other TensorFlow tutorials, but I was having very little success with them due to underfitting. So I modified the tutorial model slightly by adding one convolutional layer and one fully connected layer. This resulted in a much more reasonable accuracy. I then added dropout to avoid overfitting (the model without dropout reached 100% accurracy on the training set after 35 epochs with a batch size of 128 and a learning rate of 0.001), but the addition of the dropout seemed to underfit the data and brought no convergence. I increased the batch size help the model converge and decreased the learning rate to 0.0001.\n",
    "\n",
    "In conclusion, I chose a simple model that illustrates the method of building deep neural architectures. I tried not to focus on the size of the network, as long as the resulting accuracy was acceptable, and the training time reasonable. Afterwards, it'd be interesting to explore how this model scales with a lot more data, and evaluate what is required to extend it in order to adapt it to those cases. This will also require to train it on a more capable machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Test a Model on New Images\n",
    "\n",
    "Take several pictures of traffic signs that you find on the web or around you (at least five), and run them through your classifier on your computer to produce example results. The classifier might not recognize some local signs but it could prove interesting nonetheless.\n",
    "\n",
    "You may find `signnames.csv` useful as it contains mappings from the class id (integer) to the actual sign name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Load the images and plot them here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "# For each image, load, crop to the proper aspect ratio, resize, convert to grayscale and normalize.\n",
    "# Then, calculate the model's label prediction for it.\n",
    "\n",
    "# TODO Don't assume the aspect ratio to be square. Use image_shape as input to determine how to crop the candidates\n",
    "#      to have the same aspect ratio as the training set\n",
    "\n",
    "candidates = []\n",
    "candidates_names = []\n",
    "\n",
    "print(\"Loading, optionally cropping, resizing to {0} and finally preprocessing extra images:\\n\".format(image_shape))\n",
    "\n",
    "images_dir = \"data/extra_images\"\n",
    "for image_name in os.listdir(images_dir):\n",
    "    image_path = os.path.join(images_dir, image_name)\n",
    "    if os.path.isdir(image_path):\n",
    "        continue\n",
    "    \n",
    "    image = mpimg.imread(image_path)\n",
    "    name, ext = os.path.splitext(image_name)\n",
    "    print(\"  Handling '{0:37s}' of size {1}\".format(image_path, image.shape))\n",
    "    \n",
    "    # If the image is rectangular, crop to a square around the center, by keeping the smallest length, so that\n",
    "    # we have an identical aspect ratio as the training data\n",
    "    if image.shape[0] != image.shape[1]:\n",
    "        min_size = min(image.shape[0], image.shape[1])\n",
    "        y_start = int(np.floor((image.shape[0] - min_size) / 2))\n",
    "        y_end = int(np.floor((image.shape[0] + min_size) / 2))\n",
    "        x_start = int(np.floor((image.shape[1] - min_size) / 2))\n",
    "        x_end = int(np.floor((image.shape[1] + min_size) / 2))\n",
    "        image = image[y_start:y_end, x_start:x_end]\n",
    "        print('    Cropped to', image.shape)\n",
    "    \n",
    "    # Resize to our what our model expects\n",
    "    image = cv2.resize(image, (image_shape[1], image_shape[0]), interpolation=cv2.INTER_AREA)\n",
    "    #print('  Resized to', image.shape, 'in order to fit into the model')\n",
    "    candidates.append(image)\n",
    "    candidates_names.append(name)\n",
    "\n",
    "# Show the candidates\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = [12, 15]\n",
    "n_img_to_show = len(candidates)\n",
    "num_cols = 4\n",
    "num_rows = np.ceil(n_img_to_show / num_cols)\n",
    "k = 1\n",
    "for i in range(len(candidates)):\n",
    "    image = candidates[i]\n",
    "    subplot = plt.subplot(num_rows, num_cols, k)\n",
    "    subplot.imshow(image)\n",
    "    subplot.set_title(candidates_names[i])\n",
    "    k = k + 1\n",
    "\n",
    "print(\"\\nShowing {0} candidates:\".format(n_img_to_show))\n",
    "\n",
    "# Preprocess the candidate images to prepare them for the prediction pipeline\n",
    "candidates_processed = []\n",
    "for i in range(len(candidates)):\n",
    "    image = candidates[i]\n",
    "    image_proccessed = preprocess_image(image)\n",
    "    candidates_processed.append(image_proccessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "_Choose five candidate images of traffic signs and provide them in the report. Are there any particular qualities of the image(s) that might make classification difficult? It would be helpful to plot the images in the notebook._\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "I chose 10 images from the internet: some are similar to what the model has been trained with, others have some particularities that should pose a challenge to the model (90 km/h sign, vandalized sign, North American sign, French sign, old sign, speed limit sign with lights, etc).\n",
    "\n",
    "Also, among the things that might have a negative impact on classification, is the fact that the preprocessing might not be totally appropriate. For it 'blindly' crops the images to the expected square ratio, but does not try to center the sign in the cropped result. Properly centering the sign in the preprocessed result should have a positive impact on the prediction accurracy. Future trainings with faked data (especially by applying translations), or better preprocessing should improve this aspect.\n",
    "\n",
    "It would also be interesting to train the model with color images and balanced labels in the dataset. These are likely to improve its prediction accurracy on real images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Run the predictions here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "# For each candidate, calculate and print the predicted label\n",
    "with tf.Session() as session:\n",
    "    # Restore the persisted model\n",
    "    tf.train.Saver().restore(session, model_to_use.path)\n",
    "    print(\"Model '{0}' restored from '{1}'\\n\".format(model_to_use.name, model_to_use.path))\n",
    "    \n",
    "    predicted = session.run(tf.argmax(prediction, 1), feed_dict={features: candidates_processed, keep_prob_conv: 1, keep_prob: 1})\n",
    "    for i in range(len(candidates)):\n",
    "        print(\"Image {0:2d} '{1:15s}' has a predicted label of {2:2d}: {3}\".format(i, candidates_names[i], predicted[i], label_names[predicted[i]][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "_Is your model able to perform equally well on captured pictures or a live camera stream when compared to testing on the dataset?_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "The model shows interesting results when encountering images different from its training data.\n",
    "For example, the 90 km/h sign is predicted to be a 30 km/h sign which makes sense (other runs have preditected to be a 50 km/h sign). It is quite surprising to see the North American 'No Left Turn' predicted as 'Turn right ahead', but that could be due to the red cross on top of the sign.\n",
    "\n",
    "The vandalized 'No Entry' sign is correctly predicted, as well as the old 'No passing' French sign.\n",
    "\n",
    "The model has trouble with the Solar 50 km/h sign which is incorrectly labeled as 60 km/h.\n",
    "\n",
    "In conclusion, the model does well with images close to the images it was trained with, even if it's not totally accurate. It also seems robust to vandalized or old signs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Visualize the softmax probabilities here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "# For each candidate, get and display the top 5 predicted labels with the corresponding confidence values\n",
    "with tf.Session() as session:\n",
    "    # Restore the persisted model\n",
    "    tf.train.Saver().restore(session, model_to_use.path)\n",
    "    print(\"Model '{0}' restored from '{1}'\\n\".format(model_to_use.name, model_to_use.path))\n",
    "    \n",
    "    top_5_values, top_5_indices = session.run(tf.nn.top_k(prediction, 5), feed_dict={features: candidates_processed, keep_prob_conv: 1, keep_prob: 1})\n",
    "    for i in range(len(candidates)):\n",
    "        print(\"Top 5 predictions for image {0} '{1}':\".format(i, candidates_names[i]))\n",
    "        for j in range(len(top_5_indices[i])):\n",
    "            print('  {0:5.2f}%: Label {1:2d} - {2}'.format(top_5_values[i][j] * 100, top_5_indices[i][j], label_names[top_5_indices[i][j]][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "*Use the model's softmax probabilities to visualize the **certainty** of its predictions, [`tf.nn.top_k`](https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#top_k) could prove helpful here. Which predictions is the model certain of? Uncertain? If the model was incorrect in its initial prediction, does the correct prediction appear in the top k? (k should be 5 at most)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "The model seems to be pretty certain of its predictions, even the incorrect ones. In previous trainings, the model would give more mitigated probabilities and, if incorrect, would have most of the correct predictions in the top 5. This does not seem to be the case in this training run, which might be another sign of the overfitting of the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "_If necessary, provide documentation for how an interface was built for your model to load and classify newly-acquired images._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "I created a simple interface that loads new images, sets them to the same aspect ratio of the images that the model has been trained with, and then scales them to the size the model can process.\n",
    "\n",
    "Afterwards, each image is preprocessed in the same fashion as the training data and then fed to the model to calculate the label that the model predicts for it.\n",
    "\n",
    "In conclusion, this interface is well automated and can be easily augmented with a UI (web or desktop) for external users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: Once you have completed all of the code implementations and successfully answered each question above, you may finalize your work by exporting the iPython Notebook as an HTML document. You can do this by using the menu above and navigating to  \\n\",\n",
    "    \"**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
