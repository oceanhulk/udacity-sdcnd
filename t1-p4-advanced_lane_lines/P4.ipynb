{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Loading modules...\")\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "# pip install peakutils\n",
    "import peakutils\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Defining utility functions to find corners in chessboard images and to calculate the perspective transform...\")\n",
    "\n",
    "''' Utility function that takes a path to an image and attempts to find the chessboard corners on it, which will be later used to correct for camera distortion '''\n",
    "def findCorners(image_path, nx, ny, objpoints, imgpoints):\n",
    "    image = cv2.imread(image_path)\n",
    "    image_chess = []\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "\n",
    "    # If found, draw corners and append them to the list\n",
    "    if ret == True:\n",
    "        image_chess = np.copy(image)\n",
    "        \n",
    "        cv2.drawChessboardCorners(image_chess, (nx, ny), corners, ret)\n",
    "        \n",
    "        objp = np.zeros((nx*ny, 3), np.float32)\n",
    "        objp[:,:2] = np.mgrid[0:nx,0:ny].T.reshape(-1, 2)\n",
    "        \n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "    \n",
    "    return ret, image, image_chess, objpoints, imgpoints\n",
    "\n",
    "''' Utility function that takes a list of source and destination points and returns the perspective matrix and its inverse '''\n",
    "def calculatePerspectiveTransform(src, dst):    \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    M_inv = cv2.getPerspectiveTransform(dst, src)\n",
    "    \n",
    "    return M, M_inv\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Define a utility class to hold a group of detected points...\")\n",
    "\n",
    "''' Utility class which holds a list of x and y points and some utility values and functions to perform on them '''\n",
    "class LineData():\n",
    "    def __init__(self, x, y):\n",
    "        assert (x != None and y != None)\n",
    "        assert (len(x) == len(y))\n",
    "        self.x = np.array(x, dtype='float')\n",
    "        self.y = np.array(y, dtype='float')\n",
    "        \n",
    "        self.reset()\n",
    "    \n",
    "    '''\n",
    "    Calculates parameters of the x, y data:\n",
    "    Number of pairs, x mean and standard deviation, y range, and the x most probable value.\n",
    "    '''\n",
    "    def reset(self):\n",
    "        self.num = len(self.x)\n",
    "        self.empty = (self.num == 0)\n",
    "        \n",
    "        self.x_mean = np.mean(self.x)\n",
    "        self.x_std = np.std(self.x)\n",
    "        self.y_min = np.amin(self.y) if not self.empty else None\n",
    "        self.y_max = np.amax(self.y) if not self.empty else None\n",
    "        \n",
    "        histo, bin_edges = np.histogram(self.x, bins=10)\n",
    "        max_histo = np.max(histo)\n",
    "        max_index = np.argmax(histo)\n",
    "        \n",
    "        if (max_histo > 2):\n",
    "            self.x_max = (bin_edges[max_index+1] + bin_edges[max_index]) / 2\n",
    "        else:\n",
    "            self.x_max = self.x_mean\n",
    "    \n",
    "    ''' Append x and y points from a list of other LineData objects. Recalculates all values when called. '''\n",
    "    def append(self, line_data_list):\n",
    "        for line_data in line_data_list:\n",
    "            self.x = np.concatenate((self.x, line_data.x))\n",
    "            self.y = np.concatenate((self.y, line_data.y))\n",
    "        \n",
    "        self.reset()\n",
    "\n",
    "    ''' Performs a 2 degree fit on the x,y data. Takes a meter per pixel optional argument in x and y. '''\n",
    "    def get_fit(self, m_per_pix = (None, None)):\n",
    "        xm_per_pix = m_per_pix[0]\n",
    "        ym_per_pix = m_per_pix[1]\n",
    "        \n",
    "        if self.num < 2:\n",
    "            return None\n",
    "        \n",
    "        if (xm_per_pix == None):\n",
    "            return np.polyfit(self.y, self.x, 2)\n",
    "        else:\n",
    "            return np.polyfit(self.y * ym_per_pix, self.x * xm_per_pix, 2)\n",
    "    \n",
    "    ''' Returns a new LineData object that has outliers removed by using the x mean, standard deviation and most probable value to do the cleanup '''\n",
    "    def get_clean(self):\n",
    "        x_clean = []\n",
    "        y_clean = []\n",
    "        # print (self.num, self.x_mean, self.x_std, self.x_max)\n",
    "        epsilon = np.finfo(float).eps\n",
    "        if (self.num < 3 or self.x_std < epsilon):\n",
    "            return LineData(self.x, self.y)\n",
    "        for i in range(self.num):\n",
    "            if (abs(self.x[i] - self.x_max) < 2 * self.x_std):\n",
    "            #if (abs(self.x[i] - self.x_mean) < 2 * self.x_std):\n",
    "                x_clean.append(self.x[i])\n",
    "                y_clean.append(self.y[i])\n",
    "        \n",
    "        return LineData(x_clean, y_clean)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Define a utility class to hold information about a single line...\")\n",
    "\n",
    "''' Utility class that holds information about a single line (left or right) and provides some utility functions to perform on it '''\n",
    "class Line():\n",
    "    def __init__(self, x_size, y_size, xm_per_pix, ym_per_pix, num_y_vals, x_begin, line_list, line_data_full_all, line_data_bottom, line_data_full):\n",
    "        assert line_list != None\n",
    "        assert line_data_full_all != None and line_data_full != None\n",
    "        \n",
    "        self.x_size = x_size\n",
    "        \n",
    "        self.xm_per_pix = xm_per_pix\n",
    "        self.ym_per_pix = ym_per_pix\n",
    "        \n",
    "        self.yvals = np.linspace(0, y_size, num=num_y_vals)\n",
    "        self.y_vals_m = self.yvals * self.ym_per_pix # In meters\n",
    "        \n",
    "        self.x_begin = x_begin\n",
    "        self.line_list = line_list\n",
    "                        \n",
    "        self.line_data_full_all = line_data_full_all\n",
    "        self.line_data_bottom = line_data_bottom\n",
    "        self.line_data_full = line_data_full\n",
    "        \n",
    "        self.raw_fit = None # Fit on line_data_full_all\n",
    "        self.smooth_fit = None # Low-pass filtered fit\n",
    "        self.smooth_fit_m = None # Low-pass filtered fit in meters\n",
    "        \n",
    "        self.detected = (self.line_data_full_all.num > 2)\n",
    "        \n",
    "        self.value_at_bottom = None\n",
    "        self.value_at_middle = None\n",
    "        self.bottom_offset = None\n",
    "        self.value_at_bottom_m = None\n",
    "        self.value_at_middle_m = None\n",
    "        self.bottom_offset_m = None\n",
    "        self.radius_of_curvature = None\n",
    "    \n",
    "    ''' Utility function that returns the goodness of fit '''\n",
    "    def goodness_of_fit(self, x, y, fit):\n",
    "        fitx = fit[0] * y**2 + fit[1] * y + fit[2]\n",
    "        mean_x = np.mean(x)\n",
    "\n",
    "        # residual sum of squares\n",
    "        ss_res = np.sum((x - fitx) ** 2)\n",
    "        \n",
    "        # total sum of squares\n",
    "        ss_tot = np.sum((x - mean_x) ** 2)\n",
    "\n",
    "        # r-squared\n",
    "        r2 = 1 - (ss_res / ss_tot)\n",
    "        \n",
    "        return r2\n",
    "    \n",
    "    '''\n",
    "    Performs a fit on the current line data and uses information from the previous frames (if it exists) to smooth the fit, using a low pass filter.\n",
    "    Calculates the fit in pixels and in meters, and also the radius of curvature and the offset at the bottom of the frame.\n",
    "    '''\n",
    "    def fit(self, low_pass_a):\n",
    "        self.raw_fit = self.line_data_full_all.get_fit()\n",
    "        self.smooth_fit = self.raw_fit if len(self.line_list) == 0 else (low_pass_a * self.raw_fit + (1 - low_pass_a) * self.line_list[-1].smooth_fit)\n",
    "        \n",
    "        raw_fit_m = self.line_data_full_all.get_fit((self.xm_per_pix, self.ym_per_pix))\n",
    "        self.smooth_fit_m = raw_fit_m if len(self.line_list) == 0 else (low_pass_a * raw_fit_m + (1 - low_pass_a) * self.line_list[-1].smooth_fit_m)\n",
    "        \n",
    "        self.current_fit = self.smooth_fit\n",
    "        self.current_fitx = self.current_fit[0] * self.yvals**2 + self.current_fit[1] * self.yvals + self.current_fit[2]\n",
    "                  \n",
    "        current_fit_m = self.smooth_fit_m\n",
    "        current_fitx_m = current_fit_m[0] * self.y_vals_m**2 + current_fit_m[1] * self.y_vals_m + current_fit_m[2]\n",
    "        \n",
    "        self.value_at_bottom = self.current_fitx[-1]\n",
    "        self.value_at_middle = self.current_fitx[np.int(len(self.yvals) / 2)]\n",
    "        self.bottom_offset = self.x_size / 2 - self.value_at_bottom\n",
    "        \n",
    "        self.value_at_bottom_m = current_fitx_m[-1]\n",
    "        self.value_at_middle_m = current_fitx_m[np.int(len(self.y_vals_m) / 2)]\n",
    "        self.bottom_offset_m = (self.x_size / 2) * self.xm_per_pix - self.value_at_bottom_m\n",
    "        \n",
    "        # Evaluate radius at bottom\n",
    "        self.radius_of_curvature = ((1 + (2 * current_fit_m[0] * self.y_vals_m[-1] + current_fit_m[1])**2)**1.5) / np.absolute(2*current_fit_m[0])\n",
    "    \n",
    "    ''' Utility function to draw the detected peaks found during detection on a given image in the input '''\n",
    "    def draw_peaks(self, image, radius, color, thickness_all, thickness_full):\n",
    "        for i in range(self.line_data_full_all.num):\n",
    "            x = np.int(self.line_data_full_all.x[i])\n",
    "            y = np.int(self.line_data_full_all.y[i])\n",
    "            #cv2.circle(image, (x, y), radius, color, thickness_all)\n",
    "        for i in range(self.line_data_full.num):\n",
    "            x = np.int(self.line_data_full.x[i])\n",
    "            y = np.int(self.line_data_full.y[i])\n",
    "            cv2.circle(image, (x, y), radius, color, thickness_full)\n",
    "    \n",
    "    ''' Utility function to draw the current fit on a given image in the input '''\n",
    "    def draw_fit(self, image, color, thickness):\n",
    "        for i in range(len(self.current_fitx) - 1):\n",
    "            x1 = np.int(self.current_fitx[i])\n",
    "            x2 = np.int(self.current_fitx[i + 1])\n",
    "            y1 = np.int(self.yvals[i])\n",
    "            y2 = np.int(self.yvals[i + 1])\n",
    "            cv2.line(image, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Define a utility class to process a single frame...\")\n",
    "\n",
    "'''\n",
    "Utility class to process take a single frame of input and process it\n",
    "to detect left and right lines.\n",
    "\n",
    "Accepts an optional line_list parameter that contains a set of detected lines\n",
    "in the previous frames and which can be useful in the context of a video to\n",
    "help detecttion in the current frame.\n",
    "'''\n",
    "class Frame:\n",
    "    def __init__(self, image, title=\"\", line_list=None):\n",
    "        self.image = image\n",
    "        self.title = title\n",
    "        self.x_size = image.shape[1]\n",
    "        self.y_size = image.shape[0]\n",
    "        self.line_list_l = [x[0] for x in line_list] if line_list != None else []\n",
    "        self.line_list_r = [x[1] for x in line_list] if line_list != None else []\n",
    "        \n",
    "        self.undistorted = None\n",
    "        self.warped = None\n",
    "        self.sobelx_binary = None\n",
    "        self.sobel_angle_binary = None\n",
    "        self.h_binary = None\n",
    "        self.l_binary = None\n",
    "        self.s_binary = None\n",
    "        self.combined_binary = None\n",
    "        self.warped_fit = None\n",
    "        self.histogram = None\n",
    "        self.result = None\n",
    "        \n",
    "        self.l_line = None\n",
    "        self.r_line = None\n",
    "    \n",
    "    ''' Utility function to create a 3 channel image from a single channel image '''\n",
    "    def create_empty_3_chan_for_1_chan(self, image):\n",
    "        empty_one_channel = np.zeros_like(image).astype(np.uint8)\n",
    "        empty_three_channels = np.dstack((empty_one_channel, empty_one_channel, empty_one_channel))\n",
    "        \n",
    "        return empty_three_channels\n",
    "    \n",
    "    ''' Utility function to draw the zone between the detected lines as single lane '''\n",
    "    def draw_fit_area(self, image, color):\n",
    "        # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "        pts_left = np.array([np.transpose(np.vstack([self.l_line.current_fitx, self.l_line.yvals]))])\n",
    "        pts_right = np.array([np.flipud(np.transpose(np.vstack([self.r_line.current_fitx, self.l_line.yvals])))])\n",
    "        pts = np.hstack((pts_left, pts_right))\n",
    "        \n",
    "        cv2.fillPoly(image, np.int_([pts]), color)\n",
    "    \n",
    "    ''' Utility function to draw the lane width information (text and arrow between the two detected lines) '''\n",
    "    def draw_width_info(self, image, font_face, font_scale, color, thickness, thickness_arrow):\n",
    "        lane_width_middle_m = self.r_line.value_at_middle_m - self.l_line.value_at_middle_m\n",
    "        \n",
    "        middle_text = \"{0:5.2f}m\".format(lane_width_middle_m)\n",
    "        text_size, base_line = cv2.getTextSize(middle_text, font_face, font_scale, thickness) \n",
    "        \n",
    "        y_ref = np.int(self.y_size / 2)\n",
    "        x_middle = np.int((self.l_line.value_at_middle + self.r_line.value_at_middle) / 2 - text_size[0] / 2)\n",
    "        middle_pos = (x_middle, y_ref + text_size[1] + base_line)\n",
    "        cv2.putText(image, middle_text, middle_pos, font_face, font_scale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "        # Draw two arrows in order to have two arrowheads\n",
    "        l_x = np.int(self.l_line.value_at_middle)\n",
    "        r_x = np.int(self.r_line.value_at_middle)\n",
    "        cv2.arrowedLine(image, (l_x, y_ref), (r_x, y_ref), color, thickness_arrow)\n",
    "        cv2.arrowedLine(image, (r_x, y_ref), (l_x, y_ref), color, thickness_arrow)\n",
    "        \n",
    "    ''' Utility function to draw the lane center information and the current offset with regard to it '''\n",
    "    def draw_offset_info(self, image, font_face, font_scale, color, thickness, thickness_line, tick_height):\n",
    "        lane_center_bottom = np.int((self.r_line.value_at_bottom + self.l_line.value_at_bottom) / 2)\n",
    "        half_x_size = np.int(self.x_size / 2)\n",
    "        car_offset_from_center_m = (self.l_line.bottom_offset_m + self.r_line.bottom_offset_m) / 2\n",
    "        \n",
    "        half_tick_height = np.int(tick_height / 2)\n",
    "        quarter_tick_height = np.int(tick_height / 4)\n",
    "        \n",
    "        thickness_half_line = np.int(thickness_line / 2)\n",
    "        thickness_arrow = thickness_half_line\n",
    "        \n",
    "        # The big tick represents the center of the lane\n",
    "        pos_big_tick_start = (lane_center_bottom, self.y_size)\n",
    "        pos_big_tick_end = tuple(np.subtract(pos_big_tick_start, (0, tick_height)))\n",
    "        \n",
    "        # The small tick represents the car (center of the image)\n",
    "        pos_small_tick_start = (half_x_size, self.y_size)\n",
    "        pos_small_tick_end = tuple(np.subtract(pos_small_tick_start, (0, half_tick_height)))\n",
    "        \n",
    "        # Draw an arrow from the big tick to the small tick to represent how much the car is offset from the center\n",
    "        # Stop arrow just before the small tick starts\n",
    "        cut_arrow = thickness_half_line if (car_offset_from_center_m > 0) else -thickness_half_line\n",
    "        pos_arrow_start = tuple(np.subtract(pos_big_tick_start, (0, quarter_tick_height)))\n",
    "        pos_arrow_end = tuple(np.subtract(pos_small_tick_start, (cut_arrow, quarter_tick_height)))\n",
    "        \n",
    "        offset_text = \"{0:5.2f}m\".format(car_offset_from_center_m)\n",
    "        text_size, base_line = cv2.getTextSize(offset_text, font_face, font_scale, thickness) \n",
    "        \n",
    "        pos_text = tuple(np.subtract(pos_small_tick_end, (np.int(text_size[0] / 2), half_tick_height + base_line)))\n",
    "        \n",
    "        cv2.line(image, pos_big_tick_start, pos_big_tick_end, color, thickness_line)\n",
    "        cv2.line(image, pos_small_tick_start, pos_small_tick_end, color, thickness_half_line)\n",
    "        cv2.arrowedLine(image, pos_arrow_start, pos_arrow_end, color, thickness_arrow)\n",
    "        cv2.putText(image, offset_text, pos_text, font_face, font_scale, color, thickness, cv2.LINE_AA)\n",
    "    \n",
    "    ''' Utility function to draw the lane radius information '''\n",
    "    def draw_radii_info(self, image, font_face, font_scale, color, thickness):\n",
    "        radii_text = \"RadiusL={0:7.2f}m RadiusR={1:7.2f}m\".format(self.l_line.radius_of_curvature, self.r_line.radius_of_curvature)\n",
    "        text_size, base_line = cv2.getTextSize(radii_text, font_face, font_scale, thickness) \n",
    "        \n",
    "        pos_text = (self.x_size - text_size[0], text_size[1] + base_line)\n",
    "        \n",
    "        cv2.putText(self.result, radii_text, pos_text, font_face, font_scale, color, thickness, cv2.LINE_AA)\n",
    "    \n",
    "    ''' Utility function to draw the detection windows for a given line detection pass '''\n",
    "    def draw_windows(self, image, windows, color, thickness):\n",
    "        for window in windows:\n",
    "            cv2.rectangle(image, window[0], window[1], color, thickness)\n",
    "    \n",
    "    ''' Utility function to draw debug information (intermediate frames used for detection) on the final result image '''\n",
    "    def stack_thumbnails(self):\n",
    "        num_cols = 1\n",
    "        thumbnail_scale = 0.15\n",
    "        thumbnail_size = (np.int(self.x_size * thumbnail_scale), np.int(self.y_size * thumbnail_scale))\n",
    "        \n",
    "        #l_gray = np.dstack((self.l, self.l, self.l))\n",
    "        #s_gray = np.dstack((self.s, self.s, self.s))\n",
    "        \n",
    "        #l_binary_gray = 255 * np.dstack((self.l_binary, self.l_binary, self.l_binary))\n",
    "        #s_binary_gray = 255 * np.dstack((self.s_binary, self.s_binary, self.s_binary))\n",
    "        \n",
    "        #sobelx_binary_gray = 255 * np.dstack((self.sobelx_binary, self.sobelx_binary, self.sobelx_binary))\n",
    "        #sobel_angle_binary_gray = 255 * np.dstack((self.sobel_angle_binary, self.sobel_angle_binary, self.sobel_angle_binary))\n",
    "        \n",
    "        combined_binary_gray = 255 * np.dstack((self.combined_binary, self.combined_binary, self.combined_binary))        \n",
    "        \n",
    "        thumbnails = []\n",
    "        \n",
    "        thumbnails.append(cv2.resize(self.warped, thumbnail_size, interpolation=cv2.INTER_AREA))\n",
    "        #thumbnails.append(None)\n",
    "        \n",
    "        #thumbnails.append(cv2.resize(sobelx_binary_gray, thumbnail_size, interpolation=cv2.INTER_AREA))\n",
    "        #thumbnails.append(cv2.resize(sobel_angle_binary_gray, thumbnail_size, interpolation=cv2.INTER_AREA))\n",
    "        #thumbnails.append(cv2.resize(l_binary_gray, thumbnail_size, interpolation=cv2.INTER_AREA))\n",
    "        #thumbnails.append(cv2.resize(s_binary_gray, thumbnail_size, interpolation=cv2.INTER_AREA))\n",
    "        \n",
    "        thumbnails.append(cv2.resize(combined_binary_gray, thumbnail_size, interpolation=cv2.INTER_AREA))\n",
    "        thumbnails.append(cv2.resize(self.warped_fit, thumbnail_size, interpolation=cv2.INTER_AREA))\n",
    "        \n",
    "        for i in range(len(thumbnails)):\n",
    "            if (thumbnails[i] == None):\n",
    "                continue\n",
    "            \n",
    "            x_offset = thumbnail_size[0] * (i % num_cols)\n",
    "            y_offset = thumbnail_size[1] * np.int(i / num_cols)\n",
    "            \n",
    "            self.result[y_offset:y_offset+thumbnail_size[1], x_offset:x_offset+thumbnail_size[0]] = thumbnails[i]\n",
    "    \n",
    "    '''\n",
    "    This function takes an image and processes it using sliding windows to detect two lines, left and right.\n",
    "    \n",
    "    The search zone and width of the search windows is determined by the availability of prior information on the position of the lines.\n",
    "    Therefore, we can execute a blind search when no prior information is available, or use the prior information to execute a more narrow search\n",
    "    around existing start positions or lien fits.\n",
    "    \n",
    "    The width of sliding windows is smaller when a fit is available.\n",
    "    '''\n",
    "    def find_peaks(self, image_to_search, search_height, stride, y_top, search_width, x_begin=(None, None), fits=(None, None)):\n",
    "        assert stride <= search_height\n",
    "        \n",
    "        ''' This function will return the search range for the left and right lines dependinng on the previous detected value and whether we have a previous fit '''\n",
    "        def calc_window_size(x_previous, y, search_width, x_interval, fit):\n",
    "            assert x_previous != None\n",
    "            \n",
    "            begin, end = None, None\n",
    "            if (fit != None):\n",
    "                x_fit = np.int(fit[0] * y**2 + fit[1] * y + fit[2])\n",
    "                half_search_width = np.int(search_width / 2)\n",
    "                begin, end = x_fit - half_search_width, x_fit + half_search_width\n",
    "            else:\n",
    "                begin, end = x_previous - search_width, x_previous + search_width\n",
    "            \n",
    "            assert begin <= end\n",
    "            \n",
    "            # Adjust for out-of-range values\n",
    "            if (end < x_interval[0]):\n",
    "                begin = end = x_interval[0]\n",
    "            elif begin < x_interval[0]:\n",
    "                begin = x_interval[0]\n",
    "            \n",
    "            if (begin > x_interval[1]):\n",
    "                begin = end = x_interval[1]\n",
    "            elif (end > x_interval[1]):\n",
    "                end = x_interval[1]\n",
    "            \n",
    "            return (begin, end)\n",
    "        \n",
    "        blind_search = (x_begin[0] == None or x_begin[1] == None)\n",
    "                \n",
    "        x_previous_l = np.int(x_begin[0]) if x_begin[0] != None else None\n",
    "        x_previous_r = np.int(x_begin[1]) if x_begin[1] != None else None\n",
    "\n",
    "        x_l, y_l, x_r, y_r = [], [], [], []\n",
    "        windows_l, windows_r = [], []\n",
    "                \n",
    "        y_begin = self.y_size - search_height\n",
    "        y_end = y_top\n",
    "        assert y_begin >= y_end\n",
    "        # TODO use y_current, not y_begin and maybe a for loop?\n",
    "        while y_begin >= y_end:\n",
    "            histogram = np.sum(image_to_search[y_begin:y_begin+search_height,:], axis=0)\n",
    "\n",
    "            y_current = y_begin + search_height / 2\n",
    "\n",
    "            x_interval = (0, self.x_size)\n",
    "            (l_start, l_end) = (np.int(self.x_size / 4), np.int(self.x_size / 2)) if blind_search else calc_window_size(x_previous_l, y_current, search_width, x_interval, fits[0])\n",
    "            (r_start, r_end) = (l_end, np.int(self.x_size * (3./4))) if blind_search else calc_window_size(x_previous_r, y_current, search_width, x_interval, fits[1])\n",
    "            \n",
    "            windows_l.append(((l_start, y_begin), (l_end, y_begin + search_height)))\n",
    "            windows_r.append(((r_start, y_begin), (r_end, y_begin + search_height)))\n",
    "\n",
    "            histo_left = histogram[l_start:l_end]\n",
    "            histo_right = histogram[r_start:r_end]\n",
    "            \n",
    "            if (len(histo_left) == 0):\n",
    "                print (\"Left histogram is empty! [{0}, {1}] {2}\".format(l_start, l_end, histo_left))\n",
    "            if (len(histo_right) == 0):\n",
    "                print (\"Right histogram is empty! [{0}, {1}] {2}\".format(r_start, r_end, histo_right))\n",
    "            \n",
    "            indexes_l = peakutils.indexes(histo_left, thres=0.1, min_dist=l_end-l_start) if len(histo_left) > 0 else []\n",
    "            indexes_r = peakutils.indexes(histo_right, thres=0.1, min_dist=r_end-r_start) if len(histo_right) > 0 else []\n",
    "            \n",
    "            if(len(indexes_l) > 0):\n",
    "                x_peak_l = indexes_l[-1] + l_start\n",
    "                x_l.append(x_peak_l)\n",
    "                y_l.append(y_current)\n",
    "                x_previous_l = np.int(x_peak_l)\n",
    "                \n",
    "            if(len(indexes_r) > 0):\n",
    "                x_peak_r = indexes_r[0] + r_start\n",
    "                x_r.append(x_peak_r)\n",
    "                y_r.append(y_current)\n",
    "                x_previous_r = np.int(x_peak_r)\n",
    "            \n",
    "            y_begin = y_begin - stride\n",
    "        \n",
    "        return LineData(x_l, y_l), LineData(x_r, y_r), windows_l, windows_r\n",
    "    \n",
    "    '''\n",
    "    This is the main function that processes the current frame to detect lines.\n",
    "    It is controlled by a list of parameters provided as input.\n",
    "    \n",
    "    It calculates intermediate thresholded frames (sobel and colour channels), combines them, and performs a line detection on the combined frame.\n",
    "    If it exists, it will use the lines information from the previous frames as a detection guide.\n",
    "    It will then output a result frame that contains the information about the detected lines.\n",
    "    '''\n",
    "    def process(self, mtx, dist, M, M_inv, params):\n",
    "        self.image_undistorted = cv2.undistort(self.image, mtx, dist, None, mtx)        \n",
    "        self.warped = cv2.warpPerspective(self.image_undistorted, M, (self.x_size, self.y_size), flags=cv2.INTER_LINEAR)\n",
    "        \n",
    "        image_to_process = self.warped\n",
    "        \n",
    "        gray = cv2.cvtColor(image_to_process, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=params.sobel_kernel)\n",
    "        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=params.sobel_kernel)\n",
    "        \n",
    "        # Absolute derivatives to accentuate strong lines\n",
    "        sobelx_absolute = np.absolute(sobelx)\n",
    "        sobely_absolute = np.absolute(sobely)\n",
    "        \n",
    "        # Threshold x gradient\n",
    "        sobelx_absolute_scaled = (255 * sobelx_absolute / np.max(sobelx_absolute))#.astype(np.uint8)\n",
    "        self.sobelx_binary = np.zeros_like(sobelx_absolute_scaled)\n",
    "        self.sobelx_binary[(sobelx_absolute_scaled >= params.sobelx_threshold[0]) & (sobelx_absolute_scaled <= params.sobelx_threshold[1])] = 1\n",
    "        \n",
    "        # Threshold gradient angle\n",
    "        sobel_angle = np.arctan2(sobely_absolute, sobelx_absolute)\n",
    "        self.sobel_angle_binary = np.zeros_like(sobel_angle).astype(np.uint8)\n",
    "        self.sobel_angle_binary[(sobel_angle >= params.angle_thresh[0]) & (sobel_angle <= params.angle_thresh[1])] = 1\n",
    "        \n",
    "        # Extract the H, L and S channels\n",
    "        hls = cv2.cvtColor(image_to_process, cv2.COLOR_RGB2HLS)\n",
    "        h = hls[:,:,0]\n",
    "        l = hls[:,:,1]\n",
    "        s = hls[:,:,2]\n",
    "        \n",
    "        # Histogram equalization to attenuate lighting differences\n",
    "        h_eq = cv2.equalizeHist(h)\n",
    "        l_eq = cv2.equalizeHist(l)\n",
    "        s_eq = cv2.equalizeHist(s)\n",
    "\n",
    "        # Threshold color channels\n",
    "        self.h_binary = np.zeros_like(h_eq)\n",
    "        self.h_binary[(h_eq >= params.h_threshold[0]) & (h_eq <= params.h_threshold[1])] = 1\n",
    "        self.l_binary = np.zeros_like(l_eq)\n",
    "        self.l_binary[(l_eq >= params.l_threshold[0]) & (l_eq <= params.l_threshold[1])] = 1\n",
    "        self.s_binary = np.zeros_like(s_eq)\n",
    "        self.s_binary[(s_eq >= params.s_threshold[0]) & (s_eq <= params.s_threshold[1])] = 1\n",
    "        \n",
    "        # Combine the binary thresholds\n",
    "        self.combined_binary = np.zeros_like(self.sobelx_binary)\n",
    "        self.combined_binary[((self.l_binary == 1) | (self.s_binary == 1) | (self.sobelx_binary == 1)) & (self.sobel_angle_binary == 1)] = 1\n",
    "        \n",
    "        image_to_fit = self.combined_binary\n",
    "        \n",
    "        # Draw peaks and fit lines\n",
    "        self.warped_fit = 255 * np.dstack((image_to_fit, image_to_fit, image_to_fit)).astype(np.uint8)\n",
    "        \n",
    "        # Do a first pass to find where the lanes begin\n",
    "        x_begin_l, x_begin_r = None, None\n",
    "        line_data_bottom_l, line_data_bottom_r = None, None\n",
    "        fit_l, fit_r = None, None\n",
    "        \n",
    "        if (len(self.line_list_l) < params.max_prev_frames):\n",
    "            # We're still in the first few frames, we don't have enough confidence in the starting positions of the lines, so we'll look for them here.\n",
    "            window_size_cur = np.int(self.y_size / 3) \n",
    "            y_top = self.y_size - window_size_cur #these vals need to go into the params\n",
    "            stride_cur = np.int(params.stride_ratio * window_size_cur)\n",
    "            line_data_bottom_l, line_data_bottom_r, windows_l, windows_r = self.find_peaks(image_to_fit, window_size_cur, stride_cur, y_top, params.search_width)\n",
    "            # This should give us exactly one point\n",
    "            assert line_data_bottom_l.num == 1 and line_data_bottom_r.num == 1\n",
    "            \n",
    "            # Use the current detected points, along with the ones from the previous frames (if any), to exclude any outliers and improve the detection of the starting point\n",
    "            line_data_bottom_all_l = LineData(line_data_bottom_l.x, line_data_bottom_l.y)\n",
    "            line_data_bottom_all_r = LineData(line_data_bottom_r.x, line_data_bottom_r.y)\n",
    "            line_data_bottom_all_l.append([line.line_data_bottom for line in self.line_list_l])\n",
    "            line_data_bottom_all_r.append([line.line_data_bottom for line in self.line_list_r])\n",
    "\n",
    "            # Clean outliers\n",
    "            # We expect the lines to be almost straight here.\n",
    "            line_data_bottom_all_l = line_data_bottom_all_l.get_clean()\n",
    "            line_data_bottom_all_r = line_data_bottom_all_r.get_clean()\n",
    "            \n",
    "            # These will act as the starting positions of the lines\n",
    "            x_begin_l = np.int(line_data_bottom_all_l.x_max)\n",
    "            x_begin_r = np.int(line_data_bottom_all_r.x_max)\n",
    "            \n",
    "            # For display purposes\n",
    "            self.histogram = np.sum(image_to_fit[self.y_size-window_size_cur:self.y_size,:], axis=0)\n",
    "        else:\n",
    "            # We have enough previous frames to be confident in the starting position of the lines. We'll therefore use them.\n",
    "            x_begin_l = self.line_list_l[-1].x_begin\n",
    "            x_begin_r = self.line_list_r[-1].x_begin\n",
    "                        \n",
    "            # We'll also use the last filtered fit as a guide while detecting points on the full image\n",
    "            fit_l, fit_r = self.line_list_l[-1].smooth_fit, self.line_list_r[-1].smooth_fit\n",
    "        \n",
    "        y_top = 0\n",
    "        window_size_cur = np.int(self.y_size * params.window_size_ratio)\n",
    "        stride_cur = np.int(params.stride_ratio * window_size_cur)\n",
    "        line_data_full_l, line_data_full_r, windows_l, windows_r = self.find_peaks(image_to_fit, window_size_cur, stride_cur, y_top, params.search_width, x_begin=(x_begin_l, x_begin_r), fits=(fit_l, fit_r))\n",
    "        line_data_full_all_l = LineData(line_data_full_l.x, line_data_full_l.y)\n",
    "        line_data_full_all_r = LineData(line_data_full_r.x, line_data_full_r.y)\n",
    "        line_data_full_all_l.append([line.line_data_full for line in self.line_list_l])\n",
    "        line_data_full_all_r.append([line.line_data_full for line in self.line_list_r])\n",
    "        \n",
    "        '''\n",
    "        At this point, we have a list of detected points for the 2 lines.\n",
    "        We want to increase the chances of good detection by using the strongest line to \n",
    "        help the weakest one by bringing points from the former to the latter and offsetting them by the lane width.\n",
    "        We create two lists:\n",
    "        - Left points offset to the position of the right line. These will be used to strengthen the right line if the left one\n",
    "          is strong and the right one is weak.\n",
    "        - Vice-versa for the right points.\n",
    " \n",
    "        We execute this only if there's a big contrast between the two lines (i.e. this will not be done if we have two strong or two weak lines).\n",
    "        '''\n",
    "        # Create the offset lists\n",
    "        new_r_x = []\n",
    "        new_r_y = []\n",
    "        for i in range(line_data_full_all_l.num):\n",
    "            new_r_x.append(line_data_full_all_l.x[i] - x_begin_l + x_begin_r)\n",
    "            new_r_y.append(line_data_full_all_l.y[i])\n",
    "        new_l_x = []\n",
    "        new_l_y = []\n",
    "        for i in range(line_data_full_all_r.num):\n",
    "            new_l_x.append(line_data_full_all_r.x[i] - x_begin_r + x_begin_l)\n",
    "            new_l_y.append(line_data_full_all_r.y[i])\n",
    "        # Check the lines strength\n",
    "        line_weak_l = line_data_full_all_l.num < 20\n",
    "        line_weak_r = line_data_full_all_r.num < 20\n",
    "        line_strong_l =  line_data_full_all_l.num >= 20\n",
    "        line_strong_r =  line_data_full_all_r.num >= 20\n",
    "        # Apply\n",
    "        if (line_weak_l and line_strong_r):\n",
    "            print (\"Using right points (full={} all={}) to detect left line (full={} all={})\".format(line_data_full_r.num, line_data_full_all_r.num, line_data_full_l.num, line_data_full_all_l.num))\n",
    "            line_data_full_all_l.append([LineData(new_l_x, new_l_y)])\n",
    "        if (line_weak_r and line_strong_l):\n",
    "            print (\"Using left points (full={} all={}) to detect right line (full={} all={})\".format(line_data_full_l.num, line_data_full_all_l.num, line_data_full_r.num, line_data_full_all_r.num))\n",
    "            line_data_full_all_r.append([LineData(new_r_x, new_r_y)])\n",
    "        \n",
    "        # Finally, use our lists of points to create the left and right Line() objects\n",
    "        self.l_line = Line(self.x_size, self.y_size, params.xm_per_pix, params.ym_per_pix, params.num_y_vals, x_begin_l, self.line_list_l, line_data_full_all_l, line_data_bottom_l, line_data_full_l)\n",
    "        self.r_line = Line(self.x_size, self.y_size, params.xm_per_pix, params.ym_per_pix, params.num_y_vals, x_begin_r, self.line_list_r, line_data_full_all_r, line_data_bottom_r, line_data_full_r)\n",
    "        \n",
    "        # By this point, we must have two detected lines\n",
    "        assert self.l_line.detected and self.r_line.detected\n",
    "        \n",
    "        # Fit each line separately using the provided detection points\n",
    "        self.l_line.fit(params.low_pass_a)\n",
    "        self.r_line.fit(params.low_pass_a)\n",
    "\n",
    "        # Draw the lane onto the warped blank image\n",
    "        fill_poly_image = self.create_empty_3_chan_for_1_chan(image_to_fit)\n",
    "        self.draw_fit_area(fill_poly_image, (0, 255, 0))\n",
    "        \n",
    "        # Draw data information into a new image        \n",
    "        fill_text_image = self.create_empty_3_chan_for_1_chan(image_to_fit)\n",
    "        self.draw_width_info(fill_text_image, cv2.FONT_HERSHEY_SIMPLEX, 2.5, (255, 255, 255), 7, 3)\n",
    "        self.draw_offset_info(fill_text_image, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, 2, 8)\n",
    "        \n",
    "        # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "        fill_poly_image_dewarped = cv2.warpPerspective(fill_poly_image, M_inv, (self.x_size, self.y_size))\n",
    "        fill_text_image_dewarped = cv2.warpPerspective(fill_text_image, M_inv, (self.x_size, self.y_size))\n",
    "        \n",
    "        self.result = cv2.addWeighted(self.image_undistorted, 1, fill_poly_image_dewarped, 0.3, 0)\n",
    "        self.result = cv2.addWeighted(self.result, 1, fill_text_image_dewarped, 0.9, 0)\n",
    "        \n",
    "        self.draw_windows(self.warped_fit, windows_l, (255, 0, 0), 5)\n",
    "        self.draw_windows(self.warped_fit, windows_r, (0, 255, 0), 5)\n",
    "        \n",
    "        self.l_line.draw_peaks(self.warped_fit, 30, (255, 0, 0), 5, -1)\n",
    "        self.r_line.draw_peaks(self.warped_fit, 30, (0, 255, 0), 5, -1)\n",
    "        \n",
    "        self.l_line.draw_fit(self.warped_fit, (255, 165, 0), 15)\n",
    "        self.r_line.draw_fit(self.warped_fit, (255, 255, 0), 15)\n",
    "        \n",
    "        # Draw radii information into the final image\n",
    "        self.draw_radii_info(self.result, cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 1)\n",
    "        \n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Defining parameters...\")\n",
    "\n",
    "'''\n",
    "This class holds the parameters that will be passed to the different\n",
    "stages of the lane detection and representation pipeline.\n",
    "'''\n",
    "class Params():\n",
    "    def __init__(self):\n",
    "        # Distortion correction parameters (chessboard pattern size)\n",
    "        self.calibration_nx = 9\n",
    "        self.calibration_ny = 6\n",
    "        \n",
    "        # Input values for the perspective transformation\n",
    "        self.perspective_src = np.float32([[600, 450], [680, 450], [1130, 720], [270, 720]])\n",
    "        x_min = 430\n",
    "        x_max = 870\n",
    "        y_min = 0\n",
    "        y_max = 720\n",
    "        self.perspective_dst = np.float32([[x_min, y_min], [x_max, y_min], [x_max, y_max], [x_min, y_max]])\n",
    "        \n",
    "        self.sobel_kernel = 3\n",
    "        self.sobelx_threshold = (15, 175)\n",
    "        self.angle_thresh = (0.1 * np.pi/2, 0.5 * np.pi/2)\n",
    "        \n",
    "        self.h_threshold = (0, 160)\n",
    "        self.l_threshold = (250, 255)\n",
    "        self.s_threshold = (250, 255)\n",
    "        \n",
    "        self.window_size_ratio = 0.1 # Ratio of the search window height to the image height\n",
    "        self.stride_ratio = 1. # Ratio of the stride to the search window height\n",
    "        self.search_width = 50 # Width in pixels of the search width given a previous detection guide exists\n",
    "        \n",
    "        self.xm_per_pix = 3.7/700 # Meters per pixel in x dimension\n",
    "        self.ym_per_pix = 30/720 # Meters per pixel in y dimension\n",
    "        self.num_y_vals = 101 # Num of displayed y fit values\n",
    "        \n",
    "        self.low_pass_a = 0.5 # Low pass filter value when smoothing previous fits\n",
    "        self.max_prev_frames = 3 # Number of previous frames to be considered in a video stream\n",
    "\n",
    "params = Params()\n",
    "\n",
    "print(\"Using:\\n\\tcalibration_nx={}\\n\\tcalibration_ny={}\\n\\tperspective_src={}\\n\\tperspective_dst={}\\n\\twindow_size_ratio={}\\n\\tstride_ratio={}\\n\\tsearch_width={}\\n\\tsobel_kernel={}\\n\\tsobelx_threshold={}\\n\\tangle_thresh={}\\n\\th_threshold={}\\n\\tl_threshold={}\\n\\ts_threshold={}\" \\\n",
    "      \"\\n\\txm_per_pix={}\\n\\tym_per_pix={}\\n\\tnum_y_vals={}\\n\\tmax_prev_frames={}\\n\\tlow_pass_a={}\"\n",
    "      .format(params.calibration_nx, params.calibration_ny, params.perspective_src, params.perspective_dst, params.window_size_ratio, params.stride_ratio, params.search_width, params.sobel_kernel, params.sobelx_threshold, params.angle_thresh,\n",
    "              params.h_threshold, params.l_threshold, params.s_threshold, params.xm_per_pix, params.ym_per_pix, params.num_y_vals, params.max_prev_frames, params.low_pass_a))\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calibrate camera\n",
    "\n",
    "mtx = None\n",
    "dist = None\n",
    "objpoints = []\n",
    "imgpoints = []\n",
    "\n",
    "image_paths = []\n",
    "images = []\n",
    "images_chess = []\n",
    "\n",
    "images_dir = \"camera_cal\"\n",
    "list_images = os.listdir(images_dir)\n",
    "for image_name in list_images:\n",
    "    image_path = os.path.join(images_dir, image_name)\n",
    "    if os.path.isdir(image_path):\n",
    "        continue\n",
    "    \n",
    "    print('Handling {0}...'.format(image_path))\n",
    "    \n",
    "    ret, image, image_chess, objpoints, imgpoints = findCorners(image_path, params.calibration_nx, params.calibration_ny, objpoints, imgpoints)\n",
    "    \n",
    "    print('  Size: {0}'.format(image.shape))\n",
    "    if (not ret):\n",
    "        print('  Could not find corners on {0}'.format(image_path))\n",
    "    \n",
    "    image_paths.append(image_path)\n",
    "    images.append(image)\n",
    "    images_chess.append(image_chess)\n",
    "\n",
    "print(\"Calibrating camera...\")\n",
    "\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, image.shape[0:2], None, None)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [9, 30]\n",
    "#plt.rcParams[\"figure.autolayout\"] = True\n",
    "plt.axis('off')\n",
    "\n",
    "num_images = len(image_paths)\n",
    "num_cols = 3\n",
    "num_rows = num_images\n",
    "\n",
    "print('Displaying {0} images...'.format(num_images))\n",
    "for i in range(num_images):\n",
    "    k = num_cols * i + 1\n",
    "    \n",
    "    subplot = plt.subplot(num_rows, num_cols, k)\n",
    "    subplot.imshow(images[i])\n",
    "    subplot.set_title(image_paths[i])\n",
    "    subplot.axis('off')\n",
    "    \n",
    "    if (len(images_chess[i]) != 0):\n",
    "        subplot = plt.subplot(num_rows, num_cols, k + 1)\n",
    "        subplot.imshow(images_chess[i])\n",
    "        subplot.set_title(\"Chessboard\")\n",
    "        subplot.axis('off')\n",
    "    \n",
    "    image_undist = cv2.undistort(images[i], mtx, dist, None, mtx)\n",
    "    \n",
    "    subplot = plt.subplot(num_rows, num_cols, k + 2)\n",
    "    subplot.imshow(image_undist)\n",
    "    subplot.set_title(\"Undistorted\")\n",
    "    subplot.axis('off')\n",
    "\n",
    "plt.tight_layout(w_pad=0)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Calculating perspective transform...\")\n",
    "\n",
    "M, M_inv = calculatePerspectiveTransform(params.perspective_src, params.perspective_dst)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images_dir = \"test_images\"\n",
    "list_images = os.listdir(images_dir)\n",
    "\n",
    "print(\"Processing images in directory '{0}':\".format(images_dir))\n",
    "\n",
    "frames = []\n",
    "for image_name in list_images:\n",
    "    image_path = os.path.join(images_dir, image_name)\n",
    "    if os.path.isdir(image_path):\n",
    "        continue\n",
    "    \n",
    "    image = mpimg.imread(image_path)\n",
    "    print(\"  {0} size={1}\".format(image_path, image.shape))\n",
    "    \n",
    "    frame = Frame(image, image_name)\n",
    "    frame.process(mtx, dist, M, M_inv, params)\n",
    "    \n",
    "    frames.append(frame)\n",
    "    \n",
    "num_images = len(frames)\n",
    "\n",
    "print(\"Processed {0} images.\".format(num_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [18, 12]\n",
    "\n",
    "num_rows = num_images\n",
    "num_cols = 8\n",
    "\n",
    "fontsize = 8\n",
    "plt.axis('off')\n",
    "\n",
    "print('Showing', num_images, 'images:')\n",
    "\n",
    "k = 1\n",
    "for frame in frames:\n",
    "    subplot = plt.subplot(num_rows, num_cols, k)\n",
    "    subplot.imshow(frame.image)\n",
    "    subplot.set_title(frame.title, fontsize=fontsize)\n",
    "    subplot.axis('off')\n",
    "    \n",
    "    subplot = plt.subplot(num_rows, num_cols, k + 1)\n",
    "    subplot.imshow(frame.image_undistorted)\n",
    "    subplot.set_title(\"Undistorted\", fontsize=fontsize)\n",
    "    subplot.axis('off')\n",
    "    \n",
    "    subplot = plt.subplot(num_rows, num_cols, k + 2)\n",
    "    subplot.imshow(frame.warped)\n",
    "    subplot.set_title(\"Warped\", fontsize=fontsize)\n",
    "    subplot.axis('off')\n",
    "    \n",
    "    subplot = plt.subplot(num_rows, num_cols, k + 3)\n",
    "    subplot.imshow(frame.sobelx_binary, cmap='gray')\n",
    "    subplot.set_title(\"Sobel X Binary\", fontsize=fontsize)\n",
    "    subplot.axis('off')\n",
    "    \n",
    "    subplot = plt.subplot(num_rows, num_cols, k + 4)\n",
    "    subplot.imshow(frame.sobel_angle_binary, cmap='gray')\n",
    "    subplot.set_title(\"Sobel Angle Binary\", fontsize=fontsize)\n",
    "    subplot.axis('off')\n",
    "    \n",
    "    subplot = plt.subplot(num_rows, num_cols, k + 5)\n",
    "    subplot.imshow(frame.l_binary, cmap='gray')\n",
    "    subplot.set_title(\"L Channel Binary\", fontsize=fontsize)\n",
    "    subplot.axis('off')\n",
    "    \n",
    "    subplot = plt.subplot(num_rows, num_cols, k + 6)\n",
    "    subplot.imshow(frame.s_binary, cmap='gray')\n",
    "    subplot.set_title(\"S Channel Binary\", fontsize=fontsize)\n",
    "    subplot.axis('off')\n",
    "    \n",
    "    subplot = plt.subplot(num_rows, num_cols, k + 7)\n",
    "    subplot.imshow(frame.combined_binary, cmap='gray')\n",
    "    subplot.set_title(\"Combined Binary\", fontsize=fontsize)\n",
    "    subplot.axis('off')\n",
    "    \n",
    "    k = k + num_cols\n",
    "    \n",
    "plt.tight_layout(w_pad=0, h_pad=0, rect=[0, 0, 1, 1])\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_cols = 3\n",
    "\n",
    "print('Showing', num_images, 'images:')\n",
    "\n",
    "k = 1\n",
    "for frame in frames:\n",
    "    x_size = frame.x_size\n",
    "    y_size = frame.y_size\n",
    "    \n",
    "    subplot = plt.subplot(num_rows, num_cols, k)\n",
    "    subplot.imshow(frame.warped_fit)\n",
    "    subplot.set_title(frame.title, fontsize=fontsize)\n",
    "    subplot.axis('off')\n",
    "    \n",
    "    subplot = plt.subplot(num_rows, num_cols, k + 1)\n",
    "    subplot.plot(frame.histogram)\n",
    "    subplot.set_xlim([0, x_size])\n",
    "    subplot.set_title(\"Histogram\", fontsize=fontsize)\n",
    "    \n",
    "    subplot = plt.subplot(num_rows, num_cols, k + 2)\n",
    "    subplot.imshow(frame.result)\n",
    "    subplot.set_title(\"Result\", fontsize=fontsize)\n",
    "    subplot.axis('off')\n",
    "    \n",
    "    k = k + num_cols\n",
    "\n",
    "#plt.tight_layout(w_pad=0, h_pad=0, rect=[0, 0, 1, 1])\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Define video pipeline...\")\n",
    "\n",
    "num_f = 0\n",
    "line_list = []\n",
    "\n",
    "def reset_globals():\n",
    "    global num_f\n",
    "    global line_list\n",
    "    \n",
    "    num_f = 0\n",
    "    line_list = []\n",
    "    \n",
    "def process_image(image):\n",
    "    global num_f\n",
    "    global line_list\n",
    "    \n",
    "    frame = Frame(image, line_list=line_list)\n",
    "    frame.process(mtx, dist, M, M_inv, params)\n",
    "    \n",
    "    if (len(line_list) < params.max_prev_frames):\n",
    "        line_list.append((frame.l_line, frame.r_line))\n",
    "    else:\n",
    "        line_list = line_list[1:]\n",
    "        line_list.append((frame.l_line, frame.r_line))\n",
    "    \n",
    "    frame.stack_thumbnails()\n",
    "    \n",
    "    num_f = num_f + 1\n",
    "    \n",
    "    return frame.result\n",
    "\n",
    "def process_video(video_filename, video_out_filename):\n",
    "    print(\"Processing '{0}' and saving the result into '{1}'...\".format(video_filename, video_out_filename))\n",
    "    \n",
    "    reset_globals()\n",
    "    \n",
    "    video_clip = VideoFileClip(video_filename)#.subclip(0,1)\n",
    "\n",
    "    print(\"  Size={0} Duration={1}s {2}FPS\".format(video_clip.size, video_clip.duration, video_clip.fps))\n",
    "\n",
    "    video_clip_out = video_clip.fl_image(process_image)\n",
    "    %time video_clip_out.write_videofile(video_out_filename, audio=False)\n",
    "    \n",
    "    print(\"Done.\")\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video_out_filename = \"project_video_out.mp4\"\n",
    "process_video(\"project_video.mp4\", video_out_filename)\n",
    "\n",
    "HTML(\"\"\"\n",
    "    <video width=\"960\" height=\"540\" controls>\n",
    "      <source src=\"{0}\">\n",
    "    </video>\n",
    "    \"\"\".format(video_out_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
