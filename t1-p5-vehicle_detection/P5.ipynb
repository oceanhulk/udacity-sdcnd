{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Loading modules...\")\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "import glob\n",
    "import time\n",
    "import pickle\n",
    "import zipfile\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.ndimage.measurements import label\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Defining parameters...\")\n",
    "\n",
    "'''\n",
    "This class holds the parameters that will be passed to the different\n",
    "stages of the lane detection and representation pipeline.\n",
    "'''\n",
    "class Params():\n",
    "    def __init__(self):\n",
    "        # New params in P5\n",
    "        \n",
    "        self.output_dir = 'output'\n",
    "        self.training_images = 'data/cars'\n",
    "        self.training_images_vehicles_zip = os.path.join(self.training_images, 'vehicles.zip')\n",
    "        self.training_images_non_vehicles_zip = os.path.join(self.training_images, 'non-vehicles.zip')\n",
    "        self.training_images_vehicles = os.path.join(self.output_dir, 'vehicles')\n",
    "        self.training_images_non_vehicles = os.path.join(self.output_dir, 'non-vehicles')\n",
    "        self.pickle_file = os.path.join(self.output_dir, 'training.pickle')\n",
    "        self.hard_negative_mining_pickle_file = os.path.join(self.output_dir, 'hard_negative_mining.pickle')\n",
    "        self.test_images = 'data/test_images'\n",
    "        self.random_seed = 42\n",
    "        self.test_ratio = 0.15\n",
    "        self.heatmap_threshold = 3\n",
    "        self.prev_heatmaps = 10\n",
    "        \n",
    "        # DOWN HERE ARE PARAMS from P4\n",
    "        \n",
    "        # Distortion correction parameters (chessboard pattern size)\n",
    "        self.calibration_nx = 9\n",
    "        self.calibration_ny = 6\n",
    "        \n",
    "        # Input values for the perspective transformation\n",
    "        self.perspective_src = np.float32([[600, 450], [680, 450], [1130, 720], [270, 720]])\n",
    "        x_min = 430\n",
    "        x_max = 870\n",
    "        y_min = 0\n",
    "        y_max = 720\n",
    "        self.perspective_dst = np.float32([[x_min, y_min], [x_max, y_min], [x_max, y_max], [x_min, y_max]])\n",
    "        \n",
    "        self.sobel_kernel = 3\n",
    "        self.sobelx_threshold = (15, 175)\n",
    "        self.angle_thresh = (0.1 * np.pi/2, 0.5 * np.pi/2)\n",
    "        \n",
    "        self.h_threshold = (0, 160)\n",
    "        self.l_threshold = (250, 255)\n",
    "        self.s_threshold = (250, 255)\n",
    "        \n",
    "        self.window_size_ratio = 0.1 # Ratio of the search window height to the image height\n",
    "        self.stride_ratio = 1. # Ratio of the stride to the search window height\n",
    "        self.search_width = 50 # Width in pixels of the search width given a previous detection guide exists\n",
    "        \n",
    "        self.xm_per_pix = 3.7/700 # Meters per pixel in x dimension\n",
    "        self.ym_per_pix = 30/720 # Meters per pixel in y dimension\n",
    "        self.num_y_vals = 101 # Num of displayed y fit values\n",
    "        \n",
    "        self.low_pass_a = 0.5 # Low pass filter value when smoothing previous fits\n",
    "        self.max_prev_frames = 3 # Number of previous frames to be considered in a video stream\n",
    "\n",
    "params = Params()\n",
    "\n",
    "print(\"Using:\\n\\tparams.output_dir={}\\n\\tparams.training_images={}\\n\\tparams.training_images_vehicles_zip={}\\n\\tparams.training_images_non_vehicles_zip={}\\n\\tparams.training_images_vehicles={}\\n\\tparams.training_images_non_vehicles={} \\\n",
    "      \\n\\tparams.pickle_file={}\\n\\tparams.hard_negative_mining_pickle_file={}\\n\\tparams.test_images={}\\n\\tparams.random_seed={}\\n\\tparams.test_ratio={}\\n\\tparams.heatmap_threshold={}\\n\\tparams.prev_heatmaps={}\"\n",
    "      .format(params.output_dir, params.training_images, params.training_images_vehicles_zip, params.training_images_non_vehicles_zip, params.training_images_vehicles, params.training_images_non_vehicles, params.pickle_file, params.hard_negative_mining_pickle_file, params.test_images,\n",
    "              params.random_seed, params.test_ratio, params.heatmap_threshold, params.prev_heatmaps))\n",
    "\n",
    "print(\"Using:\\n\\tcalibration_nx={}\\n\\tcalibration_ny={}\\n\\tperspective_src={}\\n\\tperspective_dst={}\\n\\twindow_size_ratio={}\\n\\tstride_ratio={}\\n\\tsearch_width={}\\n\\tsobel_kernel={}\\n\\tsobelx_threshold={}\\n\\tangle_thresh={}\\n\\th_threshold={}\\n\\tl_threshold={}\\n\\ts_threshold={}\" \\\n",
    "      \"\\n\\txm_per_pix={}\\n\\tym_per_pix={}\\n\\tnum_y_vals={}\\n\\tmax_prev_frames={}\\n\\tlow_pass_a={}\"\n",
    "      .format(params.calibration_nx, params.calibration_ny, params.perspective_src, params.perspective_dst, params.window_size_ratio, params.stride_ratio, params.search_width, params.sobel_kernel, params.sobelx_threshold, params.angle_thresh,\n",
    "              params.h_threshold, params.l_threshold, params.s_threshold, params.xm_per_pix, params.ym_per_pix, params.num_y_vals, params.max_prev_frames, params.low_pass_a))\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare the training dataset\n",
    "\n",
    "os.makedirs(params.output_dir, exist_ok=True)\n",
    "\n",
    "# Load the dataset and create a Pickle file\n",
    "print (\"Loading the training dataset...\")\n",
    "\n",
    "print (\"\\tUnzipping the data...\")\n",
    "\n",
    "with zipfile.ZipFile(params.training_images_vehicles_zip, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(params.training_images_vehicles)\n",
    "with zipfile.ZipFile(params.training_images_non_vehicles_zip, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(params.training_images_non_vehicles)\n",
    "\n",
    "print (\"\\tDone.\")\n",
    "\n",
    "data = {'vehicles': [], 'non-vehicles': []}\n",
    "\n",
    "vehicles = data['vehicles']\n",
    "non_vehicles = data['non-vehicles']\n",
    "for filename in glob.iglob(params.training_images_vehicles + '/**/*.png', recursive=True):\n",
    "    image = mpimg.imread(filename)\n",
    "    vehicles.append(image)\n",
    "for filename in glob.iglob(params.training_images_non_vehicles + '/**/*.png', recursive=True):\n",
    "    image = mpimg.imread(filename)\n",
    "    non_vehicles.append(image)\n",
    "\n",
    "print(\"Loaded:\\n\\t{} Vehicles from '{}'\\n\\t{} Non-Vehicles from '{}'\".format(len(vehicles), params.training_images_vehicles, len(non_vehicles), params.training_images_non_vehicles))\n",
    "\n",
    "print(\"Writing the Pickle file to '{}'...\".format(params.pickle_file))\n",
    "\n",
    "with open(params.pickle_file, \"wb\") as file:\n",
    "    pickle.dump(data, file)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Running data sanity checks...\")\n",
    "\n",
    "data_shape = vehicles[0].shape\n",
    "data_type = vehicles[0].dtype\n",
    "\n",
    "for image in vehicles:\n",
    "    assert image.shape == data_shape\n",
    "    assert image.dtype == data_type\n",
    "for image in non_vehicles:\n",
    "    assert image.shape == data_shape\n",
    "    assert image.dtype == data_type\n",
    "\n",
    "print(\"All data has a shape of {} and a type of {}\".format(data_shape, data_type))\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the data from the pickle file\n",
    "\n",
    "vehicles = []\n",
    "non_vehicles = []\n",
    "\n",
    "print(\"Loading the Pickle file from '{}'...\".format(params.pickle_file))\n",
    "\n",
    "with open(params.pickle_file, \"rb\") as file:\n",
    "    data = pickle.load(file)\n",
    "    vehicles = data['vehicles']\n",
    "    non_vehicles = data['non-vehicles']\n",
    "    \n",
    "print(\"Loaded:\\n\\t{} Vehicles\\n\\t{} Non-Vehicles\".format(len(vehicles), len(non_vehicles)))\n",
    "\n",
    "if (False):\n",
    "#if (os.path.isfile(params.hard_negative_mining_pickle_file)):\n",
    "    print(\"Loading hard negative mining data Pickle file from '{}'...\".format(params.hard_negative_mining_pickle_file))\n",
    "\n",
    "    with open(params.hard_negative_mining_pickle_file, \"rb\") as file:\n",
    "        data_hard = pickle.load(file)\n",
    "        vehicles_hard = data_hard['vehicles']\n",
    "        non_vehicles_hard = data_hard['non-vehicles']\n",
    "    \n",
    "    print(\"Loaded:\\n\\t{} Vehicles\\n\\t{} Non-Vehicles\".format(len(vehicles_hard), len(non_vehicles_hard)))\n",
    "    \n",
    "    vehicles.extend(vehicles_hard)\n",
    "    non_vehicles.extend(non_vehicles_hard)\n",
    "    \n",
    "    print(\"Total is now:\\n\\t{} Vehicles\\n\\t{} Non-Vehicles\".format(len(vehicles), len(non_vehicles)))\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Data exploration...\")\n",
    "\n",
    "np.random.seed(params.random_seed)\n",
    "\n",
    "vehicle_index = np.random.randint(0, len(vehicles))\n",
    "non_vehicle_index = np.random.randint(0, len(non_vehicles))\n",
    "\n",
    "print(\"Plotting vehicle of index {} and non-vehicle of index {}\".format(vehicle_index, non_vehicle_index))\n",
    "\n",
    "vehicle_image = vehicles[vehicle_index]\n",
    "non_vehicle_image = non_vehicles[non_vehicle_index]\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.imshow(vehicle_image)\n",
    "plt.title(\"Vehicle index {}\".format(vehicle_index))\n",
    "plt.subplot(122)\n",
    "plt.imshow(non_vehicle_image)\n",
    "plt.title(\"Non-vehicle index {}\".format(non_vehicle_index))\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# FULL PIPELINE ON SINGLE IMAGE\n",
    "# Most of this code is from the lectures\n",
    "\n",
    "''' Assumes the image has been read with mpimg.imread() and is therefore in RGB format '''\n",
    "def convertImage(image, color_space='RGB'):\n",
    "    if color_space == 'RGB':\n",
    "        return image\n",
    "    elif color_space == 'HSV':\n",
    "        return cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    elif color_space == 'LUV':\n",
    "        return cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "    elif color_space == 'HLS':\n",
    "        return cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    elif color_space == 'YUV':\n",
    "        return cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "    elif color_space == 'YCrCb':\n",
    "        return cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
    "    else:\n",
    "        assert False, \"Can't handle color_space={}\".format(color_space)\n",
    "        return image\n",
    "\n",
    "# Define a function to compute binned color features  \n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    features = cv2.resize(img, size).ravel() \n",
    "    # Return the feature vector\n",
    "    return features\n",
    "\n",
    "# Define a function to compute color histogram features \n",
    "# NEED TO CHANGE bins_range if reading .png files with mpimg!\n",
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "\n",
    "    #bin_edges = rhist[1]\n",
    "    #bin_centers = (bin_edges[1:]  + bin_edges[0:len(bin_edges)-1])/2\n",
    "\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    \n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    # return rhist, ghist, bhist, bin_centers, hist_features\n",
    "    return hist_features\n",
    "\n",
    "# Define a function to return HOG features and visualization\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, vis=False, feature_vec=True):\n",
    "    if vis == True:\n",
    "        # Call with two outputs if vis==True\n",
    "        features, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell), cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=True, visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    else:\n",
    "         # Otherwise call with one output\n",
    "        features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell), cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=True, visualise=vis, feature_vector=feature_vec)\n",
    "        return features\n",
    "\n",
    "# Define a function to extract features from a single image window\n",
    "# This function is very similar to extract_features()\n",
    "# just for a single image rather than list of images\n",
    "# Define a function to extract features from a list of images\n",
    "# Have this function call bin_spatial() and color_hist()\n",
    "def single_img_features(img, color_space='RGB', spatial_size=(32, 32), hist_bins=32, orient=9, pix_per_cell=8, cell_per_block=2, hog_channel=0, spatial_feat=True, hist_feat=True, hog_feat=True):    \n",
    "    #1) Define an empty list to receive features\n",
    "    img_features = []\n",
    "    #2) Apply color conversion if other than 'RGB'\n",
    "    feature_image = convertImage(img, color_space)\n",
    "\n",
    "    #3) Compute spatial features if flag is set\n",
    "    if spatial_feat == True:\n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        #4) Append features to list\n",
    "        img_features.append(spatial_features)\n",
    "    #5) Compute histogram features if flag is set\n",
    "    if hist_feat == True:\n",
    "        hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "        #6) Append features to list\n",
    "        img_features.append(hist_features)\n",
    "    #7) Compute HOG features if flag is set\n",
    "    if hog_feat == True:\n",
    "        if hog_channel == 'ALL':\n",
    "            hog_features = []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                hog_features.extend(get_hog_features(feature_image[:,:,channel], \n",
    "                                    orient, pix_per_cell, cell_per_block, \n",
    "                                    vis=False, feature_vec=True))      \n",
    "        else:\n",
    "            hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                        pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "        #8) Append features to list\n",
    "        img_features.append(hog_features)\n",
    "\n",
    "    #9) Return concatenated array of features\n",
    "    return np.concatenate(img_features)\n",
    "\n",
    "def extract_features(imgs, color_space='RGB', spatial_size=(32, 32), hist_bins=32, orient=9, pix_per_cell=8, cell_per_block=2, hog_channel=0, spatial_feat=True, hist_feat=True, hog_feat=True):\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for image in imgs:\n",
    "        file_features = single_img_features(image, color_space=color_space, spatial_size=spatial_size, hist_bins=hist_bins, orient=orient, pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, hog_channel=hog_channel, spatial_feat=spatial_feat, hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "        \n",
    "        features.append(file_features)\n",
    "    # Return list of feature vectors\n",
    "    return features\n",
    "    \n",
    "# Define a function that takes an image,\n",
    "# start and stop positions in both x and y, \n",
    "# window size (x and y dimensions),  \n",
    "# and overlap fraction (for both x and y)\n",
    "def slide_window(img, x_start_stop=[None, None], y_start_stop=[None, None], xy_window=(64, 64), xy_overlap=(0.5, 0.5)):\n",
    "    # If x and/or y start/stop positions not defined, set to image size\n",
    "    if x_start_stop[0] == None:\n",
    "        x_start_stop[0] = 0\n",
    "    if x_start_stop[1] == None:\n",
    "        x_start_stop[1] = img.shape[1]\n",
    "    if y_start_stop[0] == None:\n",
    "        y_start_stop[0] = 0\n",
    "    if y_start_stop[1] == None:\n",
    "        y_start_stop[1] = img.shape[0]\n",
    "    # Compute the span of the region to be searched    \n",
    "    xspan = x_start_stop[1] - x_start_stop[0]\n",
    "    yspan = y_start_stop[1] - y_start_stop[0]\n",
    "    # Compute the number of pixels per step in x/y\n",
    "    nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "    ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "    # Compute the number of windows in x/y\n",
    "    nx_windows = np.int(xspan/nx_pix_per_step) - 1\n",
    "    ny_windows = np.int(yspan/ny_pix_per_step) - 1\n",
    "    # Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "    # Loop through finding x and y window positions\n",
    "    # Note: you could vectorize this step, but in practice\n",
    "    # you'll be considering windows one by one with your\n",
    "    # classifier, so looping makes sense\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            # Calculate window position\n",
    "            startx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "            endx = startx + xy_window[0]\n",
    "            starty = ys*ny_pix_per_step + y_start_stop[0]\n",
    "            endy = starty + xy_window[1]\n",
    "            \n",
    "            # Append window position to list\n",
    "            window_list.append(((startx, starty), (endx, endy)))\n",
    "    # Return the list of windows\n",
    "    return window_list\n",
    "\n",
    "# Define a function you will pass an image \n",
    "# and the list of windows to be searched (output of slide_windows())\n",
    "def search_windows(img, windows, clf, scaler, color_space='RGB', spatial_size=(32, 32), hist_bins=32, hist_range=(0, 256), orient=9, pix_per_cell=8, cell_per_block=2, hog_channel=0, spatial_feat=True, hist_feat=True, hog_feat=True):\n",
    "    #1) Create an empty list to receive positive detection windows\n",
    "    on_windows = []\n",
    "    #2) Iterate over all windows in the list\n",
    "    for window in windows:\n",
    "        #3) Extract the test window from original image\n",
    "        test_img = cv2.resize(img[window[0][1]:window[1][1], window[0][0]:window[1][0]], (64, 64))      \n",
    "        #4) Extract features for that window using single_img_features()\n",
    "        features = single_img_features(test_img, color_space=color_space, \n",
    "                            spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                            orient=orient, pix_per_cell=pix_per_cell, \n",
    "                            cell_per_block=cell_per_block, \n",
    "                            hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                            hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "        #5) Scale extracted features to be fed to classifier\n",
    "        test_features = scaler.transform(np.array(features).reshape(1, -1))\n",
    "        #6) Predict using your classifier\n",
    "        prediction = clf.predict(test_features)\n",
    "        #prediction = clf.decision_function(features)\n",
    "        #7) If positive (prediction == 1) then save the window\n",
    "        #if prediction > 0.5: #prediction == 1:\n",
    "        if prediction == 1:\n",
    "            on_windows.append(window)\n",
    "    #8) Return windows for positive detections\n",
    "    return on_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot HOG results for different values of the color_space input parameter\n",
    "\n",
    "fontsize = 8\n",
    "\n",
    "orientations = [9]\n",
    "pix_per_cells = [8]\n",
    "cell_per_block = 2\n",
    "color_spaces = ['RGB', 'YUV', 'YCrCb', 'HSV', 'LUV', 'HLS']\n",
    "num_color_spaces = len(color_spaces)\n",
    "\n",
    "for orient in orientations:\n",
    "    for pix_per_cell in pix_per_cells:\n",
    "        \n",
    "        fig = plt.figure(figsize=(10,10))\n",
    "        num_rows = num_color_spaces\n",
    "        num_cols = 3\n",
    "    \n",
    "        for i in range(num_color_spaces):\n",
    "            color_space = color_spaces[i]\n",
    "            \n",
    "            converted_image = convertImage(vehicle_image, color_space)\n",
    "            features, hog_image_0 = get_hog_features(converted_image[:,:,0], orient, pix_per_cell, cell_per_block, vis=True, feature_vec=False)\n",
    "            features, hog_image_1 = get_hog_features(converted_image[:,:,1], orient, pix_per_cell, cell_per_block, vis=True, feature_vec=False)\n",
    "            features, hog_image_2 = get_hog_features(converted_image[:,:,2], orient, pix_per_cell, cell_per_block, vis=True, feature_vec=False)\n",
    "            \n",
    "            subplot = plt.subplot(num_rows, num_cols, i * num_cols  + 1)\n",
    "            plt.imshow(hog_image_0, cmap='gray')\n",
    "            plt.title('HOG for {} channel 0'.format(color_space), fontsize=fontsize)\n",
    "            plt.axis('off')\n",
    "            \n",
    "            subplot = plt.subplot(num_rows, num_cols, i * num_cols  + 2)\n",
    "            plt.imshow(hog_image_1, cmap='gray')\n",
    "            plt.title('HOG for {} channel 1'.format(color_space), fontsize=fontsize)\n",
    "            plt.axis('off')\n",
    "            \n",
    "            subplot = plt.subplot(num_rows, num_cols, i * num_cols  + 3)\n",
    "            plt.imshow(hog_image_2, cmap='gray')\n",
    "            plt.title('HOG for {} channel 2'.format(color_space), fontsize=fontsize)\n",
    "            plt.axis('off')\n",
    "            \n",
    "        fig.tight_layout(w_pad=-2, h_pad=0, rect=[0, 0, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot HOG results for different values of the orientation input parameter\n",
    "\n",
    "orientations = [3, 5, 7, 9, 11, 13]\n",
    "pix_per_cells = [8]\n",
    "cell_per_block = 2\n",
    "color_spaces = ['YCrCb']\n",
    "num_orientations = len(orientations)\n",
    "\n",
    "for color_space in color_spaces:\n",
    "    for pix_per_cell in pix_per_cells:\n",
    "        \n",
    "        fig = plt.figure(figsize=(10,10))\n",
    "        num_rows = 2\n",
    "        num_cols = 3\n",
    "    \n",
    "        for i in range(num_orientations):\n",
    "            orient = orientations[i]\n",
    "            \n",
    "            converted_image = convertImage(vehicle_image, color_space)\n",
    "            features, hog_image_0 = get_hog_features(converted_image[:,:,0], orient, pix_per_cell, cell_per_block, vis=True, feature_vec=False)\n",
    "            \n",
    "            subplot = plt.subplot(num_rows, num_cols, (int(i / num_cols) * num_cols + (i % num_cols) + 1))\n",
    "            plt.imshow(hog_image_0, cmap='gray')\n",
    "            plt.title('HOG for {} channel 0 orientation={}'.format(color_space, orient), fontsize=fontsize)\n",
    "            plt.axis('off')\n",
    "            \n",
    "        fig.tight_layout(w_pad=0, h_pad=0, rect=[0, 0, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot HOG results for different values of the pix_per_cell input parameter\n",
    "\n",
    "orientations = [9]\n",
    "pix_per_cells = [4, 6, 8, 10, 12, 14]\n",
    "cell_per_block = 2\n",
    "color_spaces = ['YCrCb']\n",
    "num_pix_per_cells = len(pix_per_cells)\n",
    "\n",
    "for color_space in color_spaces:\n",
    "    for orient in orientations:\n",
    "        \n",
    "        fig = plt.figure(figsize=(10,10))\n",
    "        num_rows = 2\n",
    "        num_cols = 3\n",
    "    \n",
    "        for i in range(num_pix_per_cells):\n",
    "            pix_per_cell = pix_per_cells[i]\n",
    "            \n",
    "            converted_image = convertImage(vehicle_image, color_space)\n",
    "            features, hog_image_0 = get_hog_features(converted_image[:,:,0], orient, pix_per_cell, cell_per_block, vis=True, feature_vec=False)\n",
    "            \n",
    "            subplot = plt.subplot(num_rows, num_cols, (int(i / num_cols) * num_cols + (i % num_cols) + 1))\n",
    "            plt.imshow(hog_image_0, cmap='gray')\n",
    "            plt.title('HOG for {} channel 0 pix_per_cell={}'.format(color_space, pix_per_cell), fontsize=fontsize)\n",
    "            plt.axis('off')\n",
    "            \n",
    "        fig.tight_layout(w_pad=0, h_pad=0, rect=[0, 0, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Define a utility class to process a single frame...\")\n",
    "\n",
    "'''\n",
    "Utility class to process take a single frame of input and process it\n",
    "to detect cars.\n",
    "\n",
    "Accepts an optional prev_hot_windows parameter that contains a set of previous detected cars\n",
    "in the previous frames and which can be useful in the context of a video to\n",
    "help detecttion in the current frame.\n",
    "'''\n",
    "class Frame:\n",
    "    def __init__(self, image, title=\"\", prev_hot_windows=[]):\n",
    "        self.image = image\n",
    "        self.title = title\n",
    "        self.x_size = image.shape[1]\n",
    "        self.y_size = image.shape[0]\n",
    "        \n",
    "        self.search_windows = []\n",
    "        self.hot_windows = []\n",
    "        self.prev_hot_windows = prev_hot_windows\n",
    "        self.car_boxes = []\n",
    "\n",
    "        self.image_windows = None\n",
    "        self.current_heatmap = None\n",
    "        self.full_heatmap = None\n",
    "        self.thresholded_heatmap = None\n",
    "        self.labels = None\n",
    "                \n",
    "        self.result = None\n",
    "    \n",
    "    ''' Utility function to create a 3 channel image from a single channel image '''\n",
    "    def create_empty_3_chan_for_1_chan(self, image):\n",
    "        empty_one_channel = np.zeros_like(image).astype(np.uint8)\n",
    "        empty_three_channels = np.dstack((empty_one_channel, empty_one_channel, empty_one_channel))\n",
    "        \n",
    "        return empty_three_channels\n",
    "    \n",
    "    ''' Utility function to draw the zone between the detected lines as single lane '''\n",
    "    def draw_fit_area(self, image, color):\n",
    "        # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "        pts_left = np.array([np.transpose(np.vstack([self.l_line.current_fitx, self.l_line.yvals]))])\n",
    "        pts_right = np.array([np.flipud(np.transpose(np.vstack([self.r_line.current_fitx, self.l_line.yvals])))])\n",
    "        pts = np.hstack((pts_left, pts_right))\n",
    "        \n",
    "        cv2.fillPoly(image, np.int_([pts]), color)\n",
    "    \n",
    "    ''' Utility function to draw the lane width information (text and arrow between the two detected lines) '''\n",
    "    def draw_width_info(self, image, font_face, font_scale, color, thickness, thickness_arrow):\n",
    "        lane_width_middle_m = self.r_line.value_at_middle_m - self.l_line.value_at_middle_m\n",
    "        \n",
    "        middle_text = \"{0:5.2f}m\".format(lane_width_middle_m)\n",
    "        text_size, base_line = cv2.getTextSize(middle_text, font_face, font_scale, thickness) \n",
    "        \n",
    "        y_ref = np.int(self.y_size / 2)\n",
    "        x_middle = np.int((self.l_line.value_at_middle + self.r_line.value_at_middle) / 2 - text_size[0] / 2)\n",
    "        middle_pos = (x_middle, y_ref + text_size[1] + base_line)\n",
    "        cv2.putText(image, middle_text, middle_pos, font_face, font_scale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "        # Draw two arrows in order to have two arrowheads\n",
    "        l_x = np.int(self.l_line.value_at_middle)\n",
    "        r_x = np.int(self.r_line.value_at_middle)\n",
    "        cv2.arrowedLine(image, (l_x, y_ref), (r_x, y_ref), color, thickness_arrow)\n",
    "        cv2.arrowedLine(image, (r_x, y_ref), (l_x, y_ref), color, thickness_arrow)\n",
    "        \n",
    "    ''' Utility function to draw the lane center information and the current offset with regard to it '''\n",
    "    def draw_offset_info(self, image, font_face, font_scale, color, thickness, thickness_line, tick_height):\n",
    "        lane_center_bottom = np.int((self.r_line.value_at_bottom + self.l_line.value_at_bottom) / 2)\n",
    "        half_x_size = np.int(self.x_size / 2)\n",
    "        car_offset_from_center_m = (self.l_line.bottom_offset_m + self.r_line.bottom_offset_m) / 2\n",
    "        \n",
    "        half_tick_height = np.int(tick_height / 2)\n",
    "        quarter_tick_height = np.int(tick_height / 4)\n",
    "        \n",
    "        thickness_half_line = np.int(thickness_line / 2)\n",
    "        thickness_arrow = thickness_half_line\n",
    "        \n",
    "        # The big tick represents the center of the lane\n",
    "        pos_big_tick_start = (lane_center_bottom, self.y_size)\n",
    "        pos_big_tick_end = tuple(np.subtract(pos_big_tick_start, (0, tick_height)))\n",
    "        \n",
    "        # The small tick represents the car (center of the image)\n",
    "        pos_small_tick_start = (half_x_size, self.y_size)\n",
    "        pos_small_tick_end = tuple(np.subtract(pos_small_tick_start, (0, half_tick_height)))\n",
    "        \n",
    "        # Draw an arrow from the big tick to the small tick to represent how much the car is offset from the center\n",
    "        # Stop arrow just before the small tick starts\n",
    "        cut_arrow = thickness_half_line if (car_offset_from_center_m > 0) else -thickness_half_line\n",
    "        pos_arrow_start = tuple(np.subtract(pos_big_tick_start, (0, quarter_tick_height)))\n",
    "        pos_arrow_end = tuple(np.subtract(pos_small_tick_start, (cut_arrow, quarter_tick_height)))\n",
    "        \n",
    "        offset_text = \"{0:5.2f}m\".format(car_offset_from_center_m)\n",
    "        text_size, base_line = cv2.getTextSize(offset_text, font_face, font_scale, thickness) \n",
    "        \n",
    "        pos_text = tuple(np.subtract(pos_small_tick_end, (np.int(text_size[0] / 2), half_tick_height + base_line)))\n",
    "        \n",
    "        cv2.line(image, pos_big_tick_start, pos_big_tick_end, color, thickness_line)\n",
    "        cv2.line(image, pos_small_tick_start, pos_small_tick_end, color, thickness_half_line)\n",
    "        cv2.arrowedLine(image, pos_arrow_start, pos_arrow_end, color, thickness_arrow)\n",
    "        cv2.putText(image, offset_text, pos_text, font_face, font_scale, color, thickness, cv2.LINE_AA)\n",
    "    \n",
    "    ''' Utility function to draw the lane radius information '''\n",
    "    def draw_radii_info(self, image, font_face, font_scale, color, thickness):\n",
    "        radii_text = \"RadiusL={0:7.2f}m RadiusR={1:7.2f}m\".format(self.l_line.radius_of_curvature, self.r_line.radius_of_curvature)\n",
    "        text_size, base_line = cv2.getTextSize(radii_text, font_face, font_scale, thickness) \n",
    "        \n",
    "        pos_text = (self.x_size - text_size[0], text_size[1] + base_line)\n",
    "        \n",
    "        cv2.putText(self.result, radii_text, pos_text, font_face, font_scale, color, thickness, cv2.LINE_AA)\n",
    "    \n",
    "    ''' Utility function to draw the detection windows for a given line detection pass '''\n",
    "    def draw_windows(self, image, windows, color=(0, 0, 255), thickness=5):\n",
    "        for window in windows:\n",
    "            cv2.rectangle(image, window[0], window[1], color, thickness)\n",
    "    \n",
    "    ''' Utility function to draw debug information (intermediate frames used for detection) on the final result image '''\n",
    "    def stack_thumbnails(self):\n",
    "        num_cols = 1\n",
    "        thumbnail_scale = 0.15\n",
    "        thumbnail_size = (np.int(self.x_size * thumbnail_scale), np.int(self.y_size * thumbnail_scale))\n",
    "        \n",
    "        #l_gray = np.dstack((self.l, self.l, self.l))\n",
    "        #s_gray = np.dstack((self.s, self.s, self.s))\n",
    "        \n",
    "        current_heatmap = 255/np.max(self.current_heatmap) * np.dstack((self.current_heatmap, self.current_heatmap, self.current_heatmap))\n",
    "        full_heatmap = 255/np.max(self.full_heatmap) * np.dstack((self.full_heatmap, self.full_heatmap, self.full_heatmap))\n",
    "        thresholded_heatmap = 255 * np.dstack((self.thresholded_heatmap, self.thresholded_heatmap, self.thresholded_heatmap))\n",
    "        labels_max = np.max(self.labels[0]) \n",
    "        if (labels_max == 0):\n",
    "            labels_max = 1\n",
    "        labels = 255/labels_max * np.dstack((self.labels[0], self.labels[0], self.labels[0]))\n",
    "        #s_binary_gray = 255 * np.dstack((self.s_binary, self.s_binary, self.s_binary))\n",
    "        \n",
    "        #sobelx_binary_gray = 255 * np.dstack((self.sobelx_binary, self.sobelx_binary, self.sobelx_binary))\n",
    "        #sobel_angle_binary_gray = 255 * np.dstack((self.sobel_angle_binary, self.sobel_angle_binary, self.sobel_angle_binary))\n",
    "        \n",
    "        #combined_binary_gray = 255 * np.dstack((self.combined_binary, self.combined_binary, self.combined_binary))        \n",
    "        \n",
    "        thumbnails = []\n",
    "        \n",
    "        thumbnails.append(cv2.resize(current_heatmap, thumbnail_size, interpolation=cv2.INTER_AREA))\n",
    "        thumbnails.append(cv2.resize(full_heatmap, thumbnail_size, interpolation=cv2.INTER_AREA))\n",
    "        thumbnails.append(cv2.resize(thresholded_heatmap, thumbnail_size, interpolation=cv2.INTER_AREA))\n",
    "        thumbnails.append(cv2.resize(labels, thumbnail_size, interpolation=cv2.INTER_AREA))\n",
    "        #thumbnails.append(None)\n",
    "        \n",
    "        #thumbnails.append(cv2.resize(sobelx_binary_gray, thumbnail_size, interpolation=cv2.INTER_AREA))\n",
    "        #thumbnails.append(cv2.resize(sobel_angle_binary_gray, thumbnail_size, interpolation=cv2.INTER_AREA))\n",
    "        #thumbnails.append(cv2.resize(l_binary_gray, thumbnail_size, interpolation=cv2.INTER_AREA))\n",
    "        #thumbnails.append(cv2.resize(s_binary_gray, thumbnail_size, interpolation=cv2.INTER_AREA))\n",
    "        \n",
    "        #thumbnails.append(cv2.resize(combined_binary_gray, thumbnail_size, interpolation=cv2.INTER_AREA))\n",
    "        #thumbnails.append(cv2.resize(self.warped_fit, thumbnail_size, interpolation=cv2.INTER_AREA))\n",
    "        \n",
    "        for i in range(len(thumbnails)):\n",
    "            if (thumbnails[i] == None):\n",
    "                continue\n",
    "            \n",
    "            x_offset = thumbnail_size[0] * (i % num_cols)\n",
    "            y_offset = thumbnail_size[1] * np.int(i / num_cols)\n",
    "            \n",
    "            self.result[y_offset:y_offset+thumbnail_size[1], x_offset:x_offset+thumbnail_size[0]] = thumbnails[i]\n",
    "    \n",
    "    '''\n",
    "    This is the main function that processes the current frame to detect cars.\n",
    "    It is controlled by a list of parameters provided as input.\n",
    "    '''\n",
    "    def process(self, params):\n",
    "        self.result = np.copy(self.image)\n",
    "        # This code comes mostly from the lessons\n",
    "                \n",
    "        def create_heatmaps():\n",
    "            threshold = params.heatmap_threshold if self.title == \"\" else 1\n",
    "            self.current_heatmap = np.zeros_like(self.image[:,:,0]).astype(np.uint8)\n",
    "            for box in self.hot_windows:\n",
    "                self.current_heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] = 1\n",
    "            self.full_heatmap = np.copy(self.current_heatmap)\n",
    "            for box in self.prev_hot_windows:\n",
    "                self.full_heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "            self.thresholded_heatmap = np.copy(self.full_heatmap)\n",
    "            self.thresholded_heatmap[self.full_heatmap < threshold] = 0\n",
    "            self.thresholded_heatmap[self.full_heatmap >= threshold] = 1\n",
    "            self.labels = label(self.thresholded_heatmap)\n",
    "            #print(self.labels[1], 'cars found')\n",
    "            \n",
    "            self.car_boxes = []\n",
    "            for car_number in range(1, self.labels[1] + 1):\n",
    "                # Find pixels with each car_number label value\n",
    "                nonzero = (self.labels[0] == car_number).nonzero()\n",
    "                # Identify x and y values of those pixels\n",
    "                nonzeroy = np.array(nonzero[0])\n",
    "                nonzerox = np.array(nonzero[1])\n",
    "                # Define a bounding box based on min/max x and y\n",
    "                bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "                if (bbox[1][0] - bbox[0][0]) > 32 and (bbox[1][1] - bbox[0][1]) > 32:\n",
    "                    self.car_boxes.append(bbox)\n",
    "\n",
    "        image = self.image.astype(np.float32)/255 # TODO This shoule be done when reading the images!\n",
    "        \n",
    "        self.image_windows = np.copy(self.image)\n",
    "        \n",
    "        y_max = image.shape[0] - 64\n",
    "        y_tiny = 64\n",
    "        y_small = 96\n",
    "        y_big = 128\n",
    "        \n",
    "        #y_start_stop = (350, 650)\n",
    "        y_start_stop = (y_max - np.int(y_big * 1.5) - 64, y_max)\n",
    "        windows_tiny = slide_window(image, x_start_stop=[None, None], y_start_stop=y_start_stop, xy_window=(y_tiny, y_tiny), xy_overlap=(0.5, 0.5))\n",
    "        y_start_stop = (y_max - np.int(y_big * 1.5) - 64, y_max)\n",
    "        windows_small = slide_window(image, x_start_stop=[None, None], y_start_stop=y_start_stop, xy_window=(y_small, y_small), xy_overlap=(0.6, 0.6))\n",
    "        y_start_stop = (y_max - np.int(y_big * 1.5), y_max)\n",
    "        windows_big = slide_window(image, x_start_stop=[None, None], y_start_stop=y_start_stop, xy_window=(y_big, y_big), xy_overlap=(0.6, 0.6))\n",
    "        \n",
    "        self.search_windows = []\n",
    "        self.search_windows.extend(windows_tiny)\n",
    "        self.search_windows.extend(windows_small)\n",
    "        #self.search_windows.extend(windows_big)\n",
    "        \n",
    "        self.draw_windows(self.image_windows, self.search_windows)\n",
    "\n",
    "        self.hot_windows = search_windows(image, self.search_windows, svc, X_scaler, color_space=color_space, \n",
    "                                spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                                orient=orient, pix_per_cell=pix_per_cell, \n",
    "                                cell_per_block=cell_per_block, \n",
    "                                hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                                hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "        \n",
    "        create_heatmaps()\n",
    "        \n",
    "        self.draw_windows(self.result, self.car_boxes)\n",
    "        \n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SVM CLASSIFIER\n",
    "# Mostly from the lessons\n",
    "\n",
    "print(\"Training a classifier on the data...\")\n",
    "\n",
    "cars = vehicles\n",
    "notcars = non_vehicles\n",
    "\n",
    "color_space = 'YUV' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 9  # HOG orientations\n",
    "pix_per_cell = 8 # HOG pixels per cell\n",
    "cell_per_block = 2 # HOG cells per block\n",
    "hog_channel = \"ALL\" # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = (16, 16) # Spatial binning dimensions\n",
    "hist_bins = 16    # Number of histogram bins\n",
    "spatial_feat = True # Spatial features on or off\n",
    "hist_feat = True # Histogram features on or off\n",
    "hog_feat = True # HOG features on or off\n",
    "y_start_stop = [None, None] # Min and max in y to search in slide_window()\n",
    "\n",
    "print(\"\\tCreating features...\")\n",
    "\n",
    "car_features = extract_features(cars, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "notcar_features = extract_features(notcars, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "print(\"\\tDone.\")\n",
    "\n",
    "print(\"\\tScaling the data...\")\n",
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "print(\"\\tFeature vector length: {}\".format(len(X[0])))\n",
    "\n",
    "print(\"\\tDone.\")\n",
    "\n",
    "print (\"\\tSplitting the data with {}% test data\".format(params.test_ratio * 100))\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=params.test_ratio, random_state=params.random_seed)\n",
    "\n",
    "print(\"\\tTraining a linear SVC...\")\n",
    "\n",
    "# Use a linear SVC \n",
    "svc = LinearSVC()\n",
    "\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(\"\\t{} seconds to train SVC\".format(round(t2-t, 2)))\n",
    "\n",
    "# Check the score of the SVC\n",
    "print('\\tTest Accuracy of SVC = {}'.format(round(svc.score(X_test, y_test), 4)))\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images_dir = params.test_images\n",
    "list_images = os.listdir(images_dir)\n",
    "\n",
    "images_out_dir = params.output_dir\n",
    "\n",
    "print(\"Processing images in directory '{0}':\".format(images_dir))\n",
    "\n",
    "total_time = 0.\n",
    "\n",
    "frames = []\n",
    "for image_name in list_images:\n",
    "    image_path = os.path.join(images_dir, image_name)\n",
    "    if os.path.isdir(image_path):\n",
    "        continue\n",
    "    \n",
    "    image = mpimg.imread(image_path)\n",
    "    print(\"  {0:40s} size={1} type={2}\".format(image_path, image.shape, image.dtype))\n",
    "    \n",
    "    t1 = time.time()\n",
    "    frame = Frame(image, image_name)\n",
    "    frame.process(params)\n",
    "    t2 = time.time()\n",
    "    total_time = total_time + t2 - t1\n",
    "    \n",
    "    print(\"    Search windows={}\".format(len(frame.search_windows)))\n",
    "    \n",
    "    windows_name = \"windows_\" + image_name\n",
    "    windows_path = os.path.join(images_out_dir, windows_name)\n",
    "    mpimg.imsave(windows_path, frame.image_windows)\n",
    "    \n",
    "    current_heatmap = 255 * np.dstack((frame.current_heatmap, frame.current_heatmap, frame.current_heatmap))\n",
    "    thresholded_heatmap = 255 * np.dstack((frame.thresholded_heatmap, frame.thresholded_heatmap, frame.thresholded_heatmap))\n",
    "    labels_max = np.max(frame.labels[0]) \n",
    "    if (labels_max == 0):\n",
    "        labels_max = 1\n",
    "    labels = 255/labels_max * np.dstack((frame.labels[0], frame.labels[0], frame.labels[0]))\n",
    "    \n",
    "    heatmap_current_name = \"heatmap_current_\" + image_name\n",
    "    heatmap_current_path = os.path.join(images_out_dir, heatmap_current_name)\n",
    "    mpimg.imsave(heatmap_current_path, current_heatmap)\n",
    "    \n",
    "    heatmap_thresholded_name = \"heatmap_thresholded_\" + image_name\n",
    "    heatmap_thresholded_path = os.path.join(images_out_dir, heatmap_thresholded_name)\n",
    "    mpimg.imsave(heatmap_thresholded_path, thresholded_heatmap)\n",
    "    \n",
    "    labels_name = \"labels_\" + image_name\n",
    "    labels_path = os.path.join(images_out_dir, labels_name)\n",
    "    mpimg.imsave(labels_path, labels)\n",
    "    \n",
    "    result_name = \"result_\" + image_name\n",
    "    result_path = os.path.join(images_out_dir, result_name)\n",
    "    mpimg.imsave(result_path, frame.result)\n",
    "    \n",
    "    frames.append(frame)\n",
    "    \n",
    "num_images = len(frames)\n",
    "\n",
    "print(\"Processed {0} images in {1:4.2f} seconds ({2:4.2f}s per frame)\".format(num_images, total_time, total_time / num_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Showing', num_images, 'images:')\n",
    "\n",
    "fontsize = 8\n",
    "\n",
    "for frame in frames:\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    \n",
    "    plt.subplot(131)\n",
    "    plt.imshow(frame.image)\n",
    "    plt.title(frame.title, fontsize=fontsize)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(132)\n",
    "    plt.imshow(frame.image_windows)\n",
    "    plt.title(\"Search Windows\", fontsize=fontsize)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(133)\n",
    "    plt.imshow(frame.result)\n",
    "    plt.title(\"Result\", fontsize=fontsize)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    fig.tight_layout(w_pad=-2, h_pad=-10, rect=[0, 0, 1, 1])\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Showing', num_images, 'images:')\n",
    "\n",
    "for frame in frames:\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    \n",
    "    plt.subplot(131)\n",
    "    plt.imshow(frame.current_heatmap, cmap=\"gray\")\n",
    "    plt.title(\"Current Heatmap\", fontsize=fontsize)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(132)\n",
    "    plt.imshow(frame.thresholded_heatmap, cmap=\"gray\")\n",
    "    plt.title(\"Thresholded Heatmap\", fontsize=fontsize)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(133)\n",
    "    plt.imshow(frame.labels[0], cmap=\"gray\")\n",
    "    plt.title(\"Labeled Heatmap\", fontsize=fontsize)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    fig.tight_layout(w_pad=-2, h_pad=-10, rect=[0, 0, 1, 1])\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Define video pipeline...\")\n",
    "\n",
    "num_f = 0\n",
    "hot_windows = []\n",
    "hot_windows_sizes = []\n",
    "\n",
    "def reset_globals():\n",
    "    global num_f\n",
    "    global hot_windows\n",
    "    global hot_windows_sizes\n",
    "    \n",
    "    num_f = 0\n",
    "    hot_windows = []\n",
    "    hot_windows_sizes = []\n",
    "    \n",
    "def process_image(image):\n",
    "    global num_f\n",
    "    global hot_windows\n",
    "    global hot_windows_sizes\n",
    "    \n",
    "    frame = Frame(image, prev_hot_windows=hot_windows)\n",
    "    frame.process(params)\n",
    "    \n",
    "    if (len(hot_windows_sizes) >= params.prev_heatmaps):\n",
    "        size_to_cut = hot_windows_sizes[0]\n",
    "        hot_windows = hot_windows[size_to_cut:]\n",
    "        hot_windows_sizes = hot_windows_sizes[1:]\n",
    "    \n",
    "    new_boxes = []\n",
    "    #new_boxes.extend(frame.car_boxes)\n",
    "    new_boxes.extend(frame.hot_windows)\n",
    "    hot_windows.extend(new_boxes)\n",
    "    hot_windows_sizes.append(len(new_boxes))\n",
    "    #print (hot_windows)\n",
    "    \n",
    "    frame.stack_thumbnails()\n",
    "    \n",
    "    num_f = num_f + 1\n",
    "    \n",
    "    return frame.result\n",
    "\n",
    "def process_video(video_filename, video_out_filename):\n",
    "    print(\"Processing '{0}' and saving the result into '{1}'...\".format(video_filename, video_out_filename))\n",
    "    \n",
    "    reset_globals()\n",
    "    \n",
    "    video_clip = VideoFileClip(video_filename)#.subclip(38,39)\n",
    "\n",
    "    print(\"  Size={0} Duration={1}s {2}FPS\".format(video_clip.size, video_clip.duration, video_clip.fps))\n",
    "\n",
    "    video_clip_out = video_clip.fl_image(process_image)\n",
    "    %time video_clip_out.write_videofile(video_out_filename, audio=False)\n",
    "    \n",
    "    print(\"Done.\")\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video_out_filename = \"output/project_video_out.mp4\"\n",
    "process_video(\"data/project_video.mp4\", video_out_filename)\n",
    "\n",
    "HTML(\"\"\"\n",
    "    <video width=\"960\" height=\"540\" controls>\n",
    "      <source src=\"{0}\">\n",
    "    </video>\n",
    "    \"\"\".format(video_out_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Collecting hard negative mining data\n",
    "\n",
    "xy_window=(64, 64)\n",
    "\n",
    "''' Utility function to find if two bounding boxes overlap '''\n",
    "def find_overlap(bb1, bb2):\n",
    "    left1 = bb1[0][0]\n",
    "    right1 = bb1[1][0]\n",
    "    top1 = bb1[0][1]\n",
    "    bottom1 = bb1[1][1]\n",
    "    \n",
    "    left2 = bb2[0][0]\n",
    "    right2 = bb2[1][0]\n",
    "    top2 = bb2[0][1]\n",
    "    bottom2 = bb2[1][1]\n",
    "    \n",
    "    if (right2 < left1 or left2 > right1):\n",
    "        return None\n",
    "    if (bottom2 < top1 or top2 > bottom1):\n",
    "        return None\n",
    "    return ((max(left1, left2), max(top1, top2)), (min(right1, right2), min(bottom1, bottom2)))\n",
    "\n",
    "images_dir = params.test_images\n",
    "list_images = os.listdir(images_dir)\n",
    "\n",
    "print(\"Processing images in directory '{0}':\".format(images_dir))\n",
    "\n",
    "path_vehicles = os.path.join(self.output_dir, 'hard_negative_mining/vehicles')\n",
    "path_non_vehicles = os.path.join(self.output_dir, 'hard_negative_mining/non_vehicles')\n",
    "\n",
    "images_to_car_bboxes = {'test1.jpg': [((810, 400), (950, 500)), ((1040, 400), (1275, 510))],\n",
    "                        'test2.jpg': [],\n",
    "                        'test3.jpg': [((860, 405), (970, 475))],\n",
    "                        'test4.jpg': [((810, 400), (950, 500)), ((1030, 400), (1260, 500))],\n",
    "                        'test5.jpg': [((800, 400), (950, 500)), ((1080, 390), (1280, 520))],\n",
    "                        'test6.jpg': [((800, 400), (950, 500)), ((1000, 400), (1210, 505))],\n",
    "                       }\n",
    "\n",
    "for image_name in list_images:\n",
    "    image_path = os.path.join(images_dir, image_name)\n",
    "    if os.path.isdir(image_path):\n",
    "        continue\n",
    "    \n",
    "    image = mpimg.imread(image_path)\n",
    "    print(\"  {0:40s} size={1} type={2}\".format(image_path, image.shape, image.dtype))\n",
    "    \n",
    "    if (image_name in images_to_car_bboxes):\n",
    "        save_image = np.copy(image)\n",
    "        new_name = image_name.replace(\"jpg\", \"png\")\n",
    "        \n",
    "        slide_windows = slide_window(image, y_start_stop=[350, 650], xy_window=xy_window, xy_overlap=(0.5, 0.5))\n",
    "        print(\"{} bounding boxes for {}\".format(len(slide_windows), image_name))\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        vehicles_counter = 0\n",
    "        non_vehicles_counter = 0\n",
    "        for car_bb in images_to_car_bboxes[image_name]:\n",
    "            cv2.rectangle(image, car_bb[0], car_bb[1], (255, 255, 255), 5)\n",
    "        for window in slide_windows:\n",
    "            is_vehicle = False\n",
    "            cv2.rectangle(image, window[0], window[1], (255, 0, 0), 4)\n",
    "            for car_bb in images_to_car_bboxes[image_name]:\n",
    "                overlap = find_overlap(car_bb, window)\n",
    "                if (overlap != None):\n",
    "                    overlap_x = (overlap[1][0] - overlap[0][0])\n",
    "                    overlap_y = (overlap[1][1] - overlap[0][1])\n",
    "                    if (overlap_x / xy_window[0] >= 0.5 and overlap_y / xy_window[1] > 0.5):\n",
    "                        cv2.rectangle(image, window[0], window[1], (0, 0, 255), 3)\n",
    "                        #cv2.rectangle(image, overlap[0], overlap[1], (255, 255, 255), 3)\n",
    "                        is_vehicle = True\n",
    "                    else:\n",
    "                        cv2.rectangle(image, window[0], window[1], (255, 192, 0), 3)\n",
    "                    \n",
    "            if is_vehicle:\n",
    "                path = os.path.join(path_vehicles, \"{0:05d}_{1}\".format(vehicles_counter, new_name))\n",
    "                vehicles_counter += 1\n",
    "            else:\n",
    "                path = os.path.join(path_non_vehicles, \"{0:05d}_{1}\".format(non_vehicles_counter, new_name))\n",
    "                non_vehicles_counter += 1\n",
    "                \n",
    "            sub = save_image[window[0][1]:window[1][1], window[0][0]:window[1][0]]\n",
    "            mpimg.imsave(path, sub)\n",
    "        \n",
    "        plt.imshow(image)\n",
    "        plt.title(image_name, fontsize=fontsize)\n",
    "    \n",
    "# Load the dataset and create a Pickle file\n",
    "print (\"Loading the training dataset...\")\n",
    "\n",
    "data = {'vehicles': [], 'non-vehicles': []}\n",
    "\n",
    "vehicles = data['vehicles']\n",
    "non_vehicles = data['non-vehicles']\n",
    "for filename in glob.iglob(path_vehicles + '/**/*.png', recursive=True):\n",
    "    image = mpimg.imread(filename)\n",
    "    vehicles.append(image)\n",
    "for filename in glob.iglob(path_non_vehicles + '/**/*.png', recursive=True):\n",
    "    image = mpimg.imread(filename)\n",
    "    non_vehicles.append(image)\n",
    "\n",
    "print(\"Loaded:\\n\\t{} Vehicles from '{}'\\n\\t{} Non-Vehicles from '{}'\".format(len(vehicles), path_vehicles, len(non_vehicles), path_non_vehicles))\n",
    "\n",
    "print(\"Writing the Pickle file to '{}'...\".format(params.hard_negative_mining_pickle_file))\n",
    "\n",
    "with open(params.hard_negative_mining_pickle_file, \"wb\") as file:\n",
    "    pickle.dump(data, file)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
